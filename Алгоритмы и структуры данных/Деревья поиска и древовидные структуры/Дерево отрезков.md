==Опр.== **Дерево отрезков (ДО)** - [[Понятие графа|древовидная]] структура данных, применяющая ассоциативную операцию на любом подотрезке отрезка (решает задачи [[Задачи RMQ и RSQ|dynamic RMQ]] и [[Задачи RMQ и RSQ|dynamic RSQ]]).

![[Pasted image 20250727195935.png]]

## Структура

- *Для определённости будем говорить про дерево отрезков на сумму.*

В идеале сделать дерево двоичным (у каждого узла, кроме листьев, ровно два ребёнка). Для этого следует поставить во все недостающие узлы нейтральный элемент (для суммы это 0).

Каждый узел дерева содержит в себе информацию о сумме на отрезке длины $2^k\ (k \in \mathbb{Z})$. Корень дерева считает сумму на всём отрезке. Левый ребёнок каждого узла считает сумму на первой половине отрезка родителя, правый ребёнок - на второй.

Для удобства реализации узлы занумерованы (для быстрого обращения по индексу): корень имеет номер $0$, у узла с номером $k$ номерами его левого и правого ребёнка являются $2k+1$ и $2k+2$ соответственно.

***Заметим, что высота дерева при такой структуре равна $\Theta(\log n)$.***

## Инициализация

Создаётся динамический массив узлов размера $4n$, где $n$ - начальное количество элементов на отрезке. С помощью рекурсии начинается заполнение дерева:

Пусть $l = 0,\ r = n + 1,\ x = 0$ - входные данные рекурсии ($l$ и $r$ обозначают границы подотрезка, за который ответственен текущий узел), $t$ - динамический массив ДО, а $a$ - изначальный массив (отрезок из задачи), тогда
1) Если $r - l = 1$, то $t_x = a_l$ (если $l < n$, иначе $t_x = e$ (в нашем случае $e = 0$)) и мы выходим из рекурсии
2) $m = \lfloor \frac{l + r}{2} \rfloor$
3) Запускаем рекурсию с $l = l,\ r = m,\ x = 2x + 1$
4) Запускаем рекурсию с $l = m,\ r = r,\ x = 2x + 2$
5) $t_x = t_{2x + 1} \circ t_{2x+2}$ (в нашем случае $\circ\ =\ +$)

## Ответ на запрос

Сумму на подотрезке тоже будем искать рекуррентно, запускаясь от корня. Рассмотрим текущий узел на некотором шаге рекурсии. Если узел помечен как отложенный, то выполняем *проталкивание* в нём (см. ниже). Далее рассмотрим подотрезок, за который отвечает данный узел:
1) Если подотрезок полностью входит в запрос, то возвращаем значение узла (выходим из рекурсии).
2) Если подотрезок полностью не входит в запрос, то возвращаем 0 (нейтральный элемент) (и выходим из рекурсии).
3) Если же отрезок не полностью входит в запрос, то рекурсивно запускаемся от его детей, после чего складываем полученные от них значения.

#### Асимптотика и её доказательство

Пусть запрос на сумму на отрезке $[L;\ R]$. Рассмотрим некоторый узел $u$ в дереве рекурсии. Пусть расстояние от корня до $u$ равно $h$ и $u$ единственный узел в дереве рекурсии на расстоянии $h$ от корня, на котором рекурсия не заканчивается. Пусть этот узел покрывает отрезок $[l;\ r]$. Рассмотрим случаи:

1) $L \leq l$
	В этом случае либо левый сын $u$ полностью входит в запрос (если $\frac{l+r}{2} \geq R$), либо правый сын $u$ полностью не входит в запрос (если $\frac{l+r}{2} < R$). То есть в любом случае не более чем один сын остаётся в рекурсии. А так как все остальные узлы на расстоянии $h$ от корня выходят из рекурсии, то на расстоянии $h+1$ будет ровно два узла и при этом не более одного узла, на котором рекурсия не заканчивается.
2) $r \leq R$
	Данный случай эквивалентен предыдущему с точностью до замены границ. Повторяя прошлые рассуждения получаем, что на расстоянии $h+1$ будет ровно два узла и при этом не более одного узла, на котором рекурсия не заканчивается.
3) $l < L \leq R < r$
	Пусть левый сын $u$ покрывает отрезок $[l_l;\ r_l]$, а правый - $[l_r;\ r_r]$, тогда либо один из детей полностью не входит в запрос и этот случай будет эквивалентен одному из случаев выше, либо $l = l_l < L \leq r_l < r_l + 1 = l_r \leq R < r_r = r$ и в таком случае левый сын соответствует случаю 2, а правый - случаю 1. Таким образом, на расстоянии $h+1$ будет ровно два узла, и при этом на расстоянии $h+2$ будет 4 узла, но только два из них будут продолжать рекурсию и случай 3 уже повториться не сможет, поскольку отрезок был разделён.

Теперь применим метод мат. индукции, чтобы доказать, что на любом расстоянии от корня не более 4-х узлов будут задействованы в рекурсии.

База: $h = 0$ - очевидно что на таком расстоянии находится только корень и более 1-го узла не может быть задействовано.

**Предположение**: На расстоянии $h$ от корня задействовано не более 4-х узлов и не более 2-х из них продолжают рекурсию.

**Шаг**: Рассмотрим расстояние $h + 1$. 
1) Если на предыдущем шаге 0 узлов продолжают рекурсию, то на этом расстоянии нет ни одного узла в рекурсии, следовательно шаг выполнен ($0 \leq 4$)
2) Если на предыдущем шаге 1 узел продолжает рекурсию, то на этом расстоянии ровно два узла задействованы в рекурсии, а следовательно, не больше 2-х узлов её продолжают - шаг выполнен.
3) Если на предыдущем шаге 2 узла продолжают рекурсию, то значит на $h-1$ расстоянии произошёл случай 3, следовательно он больше произойти не может, следовательно каждый из этих двух узлов имеет только одного сына, который продолжает рекурсию. Итого 4 узла задействованы на этом уровне и 3 узла продолжают рекурсию - шаг выполнен.

По индукции мы доказали, что в рекурсии участвуют не более 4-х узлов на каждом уровне, следовательно, максимум действий рекурсии равно $4H$, где $H$ - высота дерева, то есть данная операция требует $O(H) = O(\log n)$ времени.

## Отложенные операции и проталкивание
### Прибавить (вычесть) на отрезке

Данную операцию будем вычислять *отложенно*: мы будем помечать что её нужно сделать, а фактически выполнять только тогда, когда потребуются обновлённые данные.

1) Так же как в ответе на запрос, мы рекурсивно спускаемся до тех ближайших вершин, которые соответствуют отрезкам, которые полностью входят в запрос (за $O(\log n)$).

2) Если одна из таких вершин - лист, то мы фактически меняем её значение на новое. 
3) Если нет, то мы помечаем вершину как отложенную и вычисляем новое значение вершины используя дистрибутивность: если старое значение вершины $x$, она покрывает отрезок $[l;\ r]$ и пришёл запрос на прибавление $y$, то отложенное значение будет равняться $x + y\cdot(r - l + 1)$. (с другими операциями аналогично).

4) При выходе из рекурсии на уровень выше, мы обновляем значение в текущей вершине, суммируя значения детей.

5) Если приходит запрос на проталкивание, то мы рекурсивно применяем 2-3 пункты для детей вершины, которую проталкиваем. После выхода из рекурсивного проталкивания применяем 4 пункт для текущей вершины.

Заметим, что одно проталкивание работает за $O(1)$, а так как проталкиваний на операцию не может быть больше чем вершин, посещённых в рекурсии, то оно просто увеличивает константу ответа на остальные запросы, не влияя на асимптотику.

- *Подобным образом можно применить любую операцию, что обладает теми же свойствами, что и исходная и обладает дистрибутивностью по отношению к ней.*
- *Подобным образом можно сделать присваивание на отрезке.*

### Заменить значение в конкретном месте

Переходим в узел, отвечающий за изменяемое место и меняем значение в нём, после последовательно от листа к корню пересчитываем значения всех его предков, складывая детей этого предка. Такая операция работает за $\Theta(\log n)$.

### Добавить новый элемент

ДО крайне медленно выполняет операцию добавления и удаления нового элемента и причём может удалять и добавлять только в конец. Не рекомендуется использовать ДО в задачах, где размер массива меняется.


1) **Аллокация**

Пока есть незадействованные листы, мы можем записывать новые значения в них, используя операцию замены значения выше. Когда же места заканчиваются мы делаем аллокацию нашего динамического массива, причём нумерация вершин изменится, поэтому за $O(n)$ придётся скопировать старые вершины на новые места и создать новый корень, а потом за $O(n)$ посчитать значения для новых узлов как при инициализации.

2) **Деаллокация**

Для ускорения структуры данных рекомендуется не делать деаллокацию или поставить критически низкую долю для деаллокации менее 10%. Выполняется так же как аллокация с копированием узлов, но так как новых не появляется, то инициализация не требуется.

## Асимптотика

**По памяти**: $O(n)$

**По времени**:
1) **Предподсчёт**: $O(n)$
2) **Обновление**: $O(\log n)$
3) **Ответ на запрос**: $O(\log n)$
4) **Аллокация**: $O(n)$

## Модификации
### Фрактальный каскад

- Теперь мы хотим добавить в наше ДО возможность ***фильтрации***. Например, сумма всех элементов, меньших $s$, или максимум среди элементов, больших $y$. Поскольку фильтрация под разные цели может занимать разное время, но при этом в основе имеет один и тот же принцип, то для удобства разберём этот принцип на задаче "найти количество элементов на отрезке  $[L;\ R]$, больших чем $m$".

В каждой вершине помимо всего прочего будем хранить отсортированную версию того подотрезка, который покрывает данная вершина. Благодаря этому, когда придёт запрос с фильтрацией, можно найти позицию элемента, значение которого равно $m$ и работать только с одной (в нашем случае правой от $m$) частью отсортированного отрезка. Найти эту позицию можно за $O(\log n)$ с помощью бинпоиска (тогда все операции с фильтрацией будут стоить $O(\log^2 n)$) или за $O(1)$, используя хитрость ниже, и в таком случае асимптотика всех операций в ДО сохранится как до модификации (не считая аллокацию).

Итак, нам нужно научиться при инициализации сортировать каждый уровень быстро и вне зависимости от других его частей. Для этого воспользуемся знакомым ранее методом - сортировкой слиянием. Если приглядеться, можно заметить, что ДО - это дерево схемы слияний, получается что при каждой операции слияния достаточно сохранять его результат в вершину дерева и будет получено корректное ДО с фрактальным каскадом.

Вспомним как происходит операция слияния: в двух частях массива слева направо двигаются указатели, сравнивая элементы под собой. Если в хеш-таблицу записать положение указателя со значением под ним в каждый момент времени, то можно будет в итоговом массиве за $O(1)$ находить место, куда вставлялся элемент с нужным значением. Только хеш-таблица в каждой вершине может стоить значительных накладных расходов, хоть и является константой. Поэтому, при сравнительно небольших входных данных пренебрегать этой константой нельзя.

#### Асимптотика в такой постановке

**По памяти**: $O(n \log n + const)$

**По времени**:
1) **Предподсчёт**: $O(n \log n)$
2) **Обновление**: $O(\log n)$
3) **Ответ на запрос**: $O(\log n)$
4) **Аллокация**: $O(n \log n)$

### Неявное (динамическое) ДО

- Теперь у нас $n \to +\infty$, но при этом изначально массив пустой (заполнен нейтральными элементами). Мы будем строить ДО не сразу, а по мере необходимости.

1) Изначально ДО состоит только из корня, который покрывает отрезок $[0;\ 0]$. И внутренняя константа $size = 0$. При такой модификации ДО строится не с помощью массива, а на ссылочных узлах.
2) При поступлении запросе на отрезке (запрос в точке рассматривается как запрос на отрезке длины 1) $[L;\ R]$:
	1) Если $R > size$, то начинается достройка дерева:
		1) $size$ увеличивается вдвое
		2) Добавляется новая вершина, которая становится новым корнем и покрывает отрезок $[0;\ size]$
		3) Бывший корень переподвешивается как левый сосед нового корня
		4) Выполняется пересчёт значения корня
		5) Заново выполняется проверка пункта 2.1
	2) Далее начинает выполнятся сам запрос:
		1) Если запрос типа GET, то по существующим вершинам он идёт как в обычном ДО, а при попытке зайти в несуществующую вершину, возвращает нейтральный элемент.
		2) Если запрос на изменение (добавление, проталкивание), то по существующим вершинам он идёт как в обычном ДО, а при попытке зайти в несуществующую вершину, создаёт её и вычисляет значение в ней.

#### Асимптотика в такой постановке

**По памяти**: $O(size)$

**По времени**:
1) **Предподсчёт**: $O(1)$
2) **Обновление**: $O(\log (R \cdot size))$
3) **Ответ на запрос**: $O(\log (R \cdot size))$

### Сжатие координат

Если задача является [[Задачи RMQ и RSQ|offline RMQ/RSQ]], то можно использовать **сжатие координат**: занумеровать только использованные позиции и построить обычное ДО на них, отдельно обрабатывая только границы запросов. Эта модификация значительно сжимает ДО, уменьшая требуемые время и память.
