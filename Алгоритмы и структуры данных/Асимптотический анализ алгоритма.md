# Введение в алгоритмизацию

**Алгоритм** — это строго детерминированная, конечная последовательность чётко определённых инструкций или правил, предназначенная для решения конкретной задачи или класса задач за конечное число шагов.

На практике нас интересуют более оптимальные алгоритмы: если два алгоритма выполняют одну и ту же задачу, но один из них всегда это делает быстрее и при этом потребляет меньше памяти устройства, на котором производятся вычисления, то очевидно предпочтение при использовании будет отдано ему.

Время, за которое алгоритм выполнит свою задачу, зависит от нескольких факторов:
- Реализация алгоритма
- Объём входных данных
- Вычислительные мощности устройства
- ЯП, на котором написан алгоритм
- и др.

То есть один и тот же алгоритм может тратить разное время в разных обстоятельствах. Поэтому при анализе алгоритма на эффективность используют *асимптотический анализ* (см. матан). При этом смотрят зависимость времени/памяти от ***объёма входных данных*** на бесконечности. В чём измерять память понятно: в минимальной единице одновременной обработки компьютером - в байтах. Про время сложнее - различия в частоте тактов процессоров и прочие различия не позволяют измерять алгоритмическое время в стандартных единицах. Поэтому принято измерять время в ***элементарных операциях*** - операциях, на выполнение которых устройство тратит значительно меньше реального времени по сравнению с другими (условно - один такт). При одинаковом коде количество элементарных операций, выполненное данным алгоритмом, является инвариантом для фиксированных входных данных.

К элементарным операциям относятся:
1) Выделение/удаление области памяти для новой переменной
2) Копирование байта из одной ячейки памяти в другую
3) Запись в ячейку памяти
4) Сложение/умножение/вычитание/деление/сравнение чисел
5) Выполнение условных конструкций при посчитанном условии (`if-else`)

# Асимптотический анализ
- *Будем рассматривать асимптотический анализ по времени. По памяти - аналогично.*

Пусть $f : \mathbb{N} \to \mathbb{N}$ - зависимость количества элементарных операций от объёма входных данных алгоритма, а $g : \mathbb{N} \to \mathbb{N}$ - некоторая функция, тогда...

==Опр.== $f = O(g)$ $\Longleftrightarrow$ $\exists C > 0\ \forall n \in \mathbb{N}\ :\ f(n) \leq C \cdot g(n)$ - **оценка сверху на алгоритм** (алгоритм $f$ выполняет не более $O(g)$ элементарных операций) 

Заметим, что данное $O$-большое - это то же $O$-большое что и в математическом асимптотическом анализе, но для удобство в алгоритмах всегда рассматривается $n \to +\infty$ и в качестве определений берётся одно из следствий исходного определения.

==Опр.== $f = \Omega(g)$ $\Longleftrightarrow$ $\exists C > 0\ \exists N \in \mathbb{N}\ \forall n \geq N\ :\ f(n) \geq C \cdot g(n)$ - **оценка снизу на алгоритм**

==Опр.== $f = \Theta(g)$ $\Longleftrightarrow$ $\exists C_1, C_2 > 0\ \exists N \in \mathbb{N}\ \forall n \geq N\ :\ C_1 \cdot g(n) \leq f(n) \leq C_2 \cdot g(n)$ - **точная оценка алгоритма**

==Опр.== $f = o(g)$ $\Longleftrightarrow$ $\forall C > 0\ \exists N \in \mathbb{N}\ \forall n \geq N\ :\ f(n) < C \cdot g(n)$ - *($f$ асимптотически строго лучше $g$)*

==Опр.== $f = \omega(g)$ $\Longleftrightarrow$ $\forall C > 0\ \exists N \in \mathbb{N}\ \forall n \geq N\ :\ f(n) > C \cdot g(n)$ - *($f$ асимптотически строго хуже $g$)*

==Опр.== $f = \theta(g)$ $\Longleftrightarrow$ $\forall C_1 > 0\ \forall C_2 > 0\ \exists N \in \mathbb{N}\ \forall n \geq N\ :\ C_1 \cdot g(n) < f(n) < C_2 \cdot g(n)$ - *(относительная погрешность между $f$ и $g$ стремится к 0)*

Заметим, что в силу арифметических свойств алгоритма $$\forall a, b = const\ :\ \log_an = \frac{\log_bn}{\log_ba} = C \cdot \log_bn\ \ \ (C = const)$$То есть в асимптотическом анализе основание логарифма не имеет значения, поэтому далее логарифм будем писать без основания (часто подразумевая основание 2, но, опять же, это не играет роли).

#### Эквивалентные определения нотаций через предел

| Нотация         | Определение через предел                                      |
| --------------- | ------------------------------------------------------------- |
| $f = O(g)$      | $\lim\limits_{n \to \infty} \frac{f(n)}{g(n)} < \infty$       |
| $f = \Theta(g)$ | $\lim\limits_{n \to \infty} \frac{f(n)}{g(n)} \in \mathbb{R}$ |
| $f = \Omega(g)$ | $\lim\limits_{n \to \infty} \frac{f(n)}{g(n)} > 0$            |
| $f = o(g)$      | $\lim\limits_{n \to \infty} \frac{f(n)}{g(n)} = 0$            |
| $f = \theta(g)$ | $\lim\limits_{n \to \infty} \frac{f(n)}{g(n)} = 1$            |
| $f = \omega(g)$ | $\lim\limits_{n \to \infty} \frac{f(n)}{g(n)} = \infty$       |

## Инструменты асимптотического анализа

### Мастер-Теорема

Пусть $T(n)$ - функция времени работы рекурсивного алгоритма от объёма входных данных, $a \in \mathbb{N}\ \ (a \geq 1)$ - количество рекурсивных вызовов алгоритма, $b \in \mathbb{N}\ \ (b > 1)$ - коэффициент деления входных данных при рекурсии, $c \in \mathbb{R}^+$ - некоторая константа, а $f : \mathbb{N} \to \mathbb{N}$ (т.ч. $f(n) = \Theta(n^c)$) - функция времени работы для разбиения задачи и комбинирования результатов (нерекурсивная часть алгоритма), тогда если $T(1) = O(1)$ и если
$$T(n) = a \cdot T(\frac{n}{b}) + f(n)$$
то при $c > \log_ba$:
$$T(n) = \Theta(n^c)$$
при $c = \log_ba$:
$$T(n) = \Theta(n^c \log n)$$
при $c < \log_ba$:
$$T(n) = \Theta(n^{\log_ba})$$

#### Доказательство.

Рассмотрим $k$-й шаг рекурсии, на нём:
- $a^k$ имеющихся подзадач
- Размер каждой подзадачи равен $\frac{n}{b^k}$
- Время на разбиение и комбинирование уровня равно $a^k \cdot f(\frac{n}{b^k})$

Просуммируем все уровни рекурсии и получим суммарное время:
$$T(n) = \sum\limits_{k=0}^{\log_bn}{a^k \Theta((\frac{n}{b^k})^c)} = \Theta(n^c \sum\limits_{k=0}^{\log_bn}{(\frac{a}{b^c})^k})$$

1) Если $c > \log_ba$, то та сумма - убывающая геометрическая прогрессия и она сходится к константе, следовательно $T(n) = \Theta(n^c)$
2) Если $c = \log_ba$, то каждый член суммы равен $1$ и вся сумма равна $\Theta(\log n)$, то есть $T(n) = \Theta(n^c)$
3) Если $c < \log_ba$, то так как $(\frac{a}{b^c})^{\log_bn} \leq \sum\limits_{k=0}^{\log_bn}{(\frac{a}{b^c})^k} \leq \log_bn \cdot (\frac{a}{b^c})^{\log_bn}$, получается $\sum\limits_{k=0}^{log_bn}{(\frac{a}{b^c})^k} = \Theta((\frac{a}{b^c})^{\log_bn})$ и в итоге $T(n) = \Theta(n^{\log_ba})$.
