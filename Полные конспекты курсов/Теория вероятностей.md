<h1><center>Теория вероятностей</center></h1>
<div style="height: 35%;"></div>
<h3><center>Автор: Ряжских Дмитрий</center></h3>
<h4><center>Семинарист: Андрей Вадимович Булинский</center></h4>
<div style="height: 42%;"></div>
<h6><center>Физтех, Декабрь 2025</center></h6>
<div style="page-break-after: always;"></div>
<h2><center>Содержание</center></h2>
[[_TOC_]]
<a href="#p1">- Дискретное вероятностное пространство</a>
<div  style="margin-left: 20px;"><a href="#p1p1">- Понятие вероятностного пространства</a></div>
<div  style="margin-left: 20px;"><a href="#p1p2">- Однородное вероятностное пространство</a></div>
<div  style="margin-left: 20px;"><a href="#p1p3">- Операции над событиями</a></div>
<div  style="margin-left: 20px;"><a href="#p1p4">- Условная вероятность</a></div>
<div  style="margin-left: 40px;"><a href="#p1p4p1">- Понятие условной вероятности</a></div>
<div  style="margin-left: 40px;"><a href="#p1p4p2">- Полная вероятность</a></div>
<div  style="margin-left: 40px;"><a href="#p1p4p3">- Задача Монти Холла</a></div>
<div  style="margin-left: 20px;"><a href="#p1p5">- Зависимость и независимость событий</a></div>
<div  style="margin-left: 20px;"><a href="#p1p6">- Дискретные случайные величины</a></div>
<div  style="margin-left: 40px;"><a href="#p1p6p1">- Понятие дискретной случайной величины</a></div>
<div  style="margin-left: 40px;"><a href="#p1p6p2">- Схема Бернулли</a></div>
<div  style="margin-left: 40px;"><a href="#p1p6p3">- Матожидание ДСВ</a></div>
<div  style="margin-left: 40px;"><a href="#p1p6p4">- Дисперсия ДСВ</a></div>
<div  style="margin-left: 40px;"><a href="#p1p6p5">- Центрирование и нормирование СВ</a></div>
<div  style="margin-left: 40px;"><a href="#p1p6p6">- Независимость СВ</a></div>
<a href="#p2">- Стохастическое вероятностное пространство</a>
<div  style="margin-left: 20px;"><a href="#p2p1">- Аксиоматика Колмогорова</a></div>
<div  style="margin-left: 20px;"><a href="#p2p02">- Геометрическая вероятность</a></div>
<div  style="margin-left: 40px;"><a href="#p2p02p1">- Парадокс Бертрана</a></div>
<div  style="margin-left: 20px;"><a href="#p2p2">- Стохастические случайные величины</a></div>
<div  style="margin-left: 40px;"><a href="#p2p2p1">- Понятие случайной величины</a></div>
<div  style="margin-left: 40px;"><a href="#p2p2p2">- Понятие случайного вектора</a></div>
<div  style="margin-left: 40px;"><a href="#p2p2p3">- Независимость случайных величин</a></div>
<div  style="margin-left: 20px;"><a href="#p2p3">- Математическое ожидание</a></div>
<div  style="margin-left: 20px;"><a href="#p2p4">- Дисперсия</a></div>
<div  style="margin-left: 20px;"><a href="#p2p5">- Ковариация</a></div>
<div  style="margin-left: 20px;"><a href="#p2p6">- Корреляция СВ</a></div>
<div  style="margin-left: 40px;"><a href="#p2p6p2">- Задача о линейном прогнозе</a></div>
<div  style="margin-left: 20px;"><a href="#p2p7">- Неравенства Чебышёва-Маркова</a></div>
<a href="#p3">- Распределение случайных величин</a>
<div  style="margin-left: 20px;"><a href="#p3p1">- Функция распределения</a></div>
<div  style="margin-left: 20px;"><a href="#p3p2">- Плотность распределения</a></div>
<div  style="margin-left: 20px;"><a href="#p3p3">- Совместное распределение СВ</a></div>
<div  style="margin-left: 20px;"><a href="#p3p4">- Характеристическая функция СВ</a></div>
<div  style="margin-left: 20px;"><a href="#p3p5">- Табличные виды распределений</a></div>
<div  style="margin-left: 40px;"><a href="#p3p5p1">- Распределение Бернулли</a></div>
<div  style="margin-left: 40px;"><a href="#p3p5p2">- Биномиальное распределение</a></div>
<div  style="margin-left: 40px;"><a href="#p3p5p3">- Распределение Пуассона</a></div>
<div  style="margin-left: 40px;"><a href="#p3p5p4">- Равномерное распределение</a></div>
<div  style="margin-left: 40px;"><a href="#p3p5p5">- Экспоненциальное распределение</a></div>
<div  style="margin-left: 40px;"><a href="#p3p5p6">- Треугольное распределение</a></div>
<div  style="margin-left: 40px;"><a href="#p3p5p7">- Распределение Коши</a></div>
<div  style="margin-left: 40px;"><a href="#p3p5p8">- Нормальное распределение</a></div>
<a href="#p4">- Последовательности случайных величин</a>
<div  style="margin-left: 20px;"><a href="#p4p1">- Лемма Бореля-Кантелли</a></div>
<div  style="margin-left: 20px;"><a href="#p4p2">- Сходимости случайных величин</a></div>
<div  style="margin-left: 40px;"><a href="#p4p2p1">- Сходимость почти наверное</a></div>
<div  style="margin-left: 40px;"><a href="#p4p2p2">- Сходимость по вероятности</a></div>
<div  style="margin-left: 40px;"><a href="#p4p2p3">- Сходимость по распределению</a></div>
<div  style="margin-left: 40px;"><a href="#p4p2p4">- Слабая сходимость</a></div>
<div  style="margin-left: 40px;"><a href="#p4p2p5">- Сходимость в среднем</a></div>
<div  style="margin-left: 20px;"><a href="#p4p3">- Законы больших чисел</a></div>


<div style="height: 120px;">БЛОК</div>

<h4><center>Базовый минимум пройденных курсов</center></h4>

<p align="justify">Прежде чем начать читать этот конспект, настоятельно рекомендуется пройти следующие курсы:</p>

1) Теория меры и интеграл Лебега
2) Линейная алгебра
<div style="page-break-after: always;"></div>

# <h1 id="p1"><center>Дискретное вероятностное пространство</center></h1>
## <h2 id="p1p1"><center>Понятие вероятностного пространства</center></h2>

==Опр.== **Вероятностная модель** - это математическая конструкция, предназначенная для формального описания случайного эксперимента, процесса или явления. Она позволяет количественно оценивать неопределенность и делать прогнозы о возможных исходах.

==Опр.== **Элементарное событие** *(элементарный исход, ЭИ)* - неделимый, абсолютно случайный объект произвольной природы. *(Обозначается как $\omega$)*

==Опр.== **Пространство элементарных исходов**  $\Omega = \{\omega_i| i \in I \subseteq \mathbb{N},\ I \neq \emptyset\}$ - (не более чем счётное непустое) множество ЭИ.

==Опр.== **Событие** - множество, состоящее из элементарных исходов (или пустое множество). 

> [!important] Говорят
> Событие $A$ случилось $\iff \exists \omega \in A$, т.ч. $\omega$ наступил

==Опр.== **Класс событий пространства ЭИ** $\mathcal{F} = 2^{\Omega}$ - совокупность всех возможных событий.

==Опр.== **Вероятность** *(вероятностная мера)* - функция $P\ :\ \mathcal{F} \to [0;\ 1]$, со следующими свойствами:
1) $P(\emptyset) = 0$
2) $P(\Omega) = 1$
3) $P(\bigsqcup\limits_{k=1}^{\infty} A_k) = \sum\limits_{k=1}^{\infty} P(A_k)$ - *свойство счётной аддитивности*

> [!warning] Важно
> Вероятность существует только в рамках некоторой вероятностной модели. Без модели НЕЛЬЗЯ говорить о какой-либо вероятности. 

==Опр.== **Невозможное событие** ($A$) - $P(A) = 0$.

==Опр.== **Достоверное событие** ($A$) - $P(A) = 1$.

==Опр.== **Дискретное вероятностное пространство (ДВП)** - вероятностная модель вида $(\Omega,\ \mathcal{F},\ P)$. ^41cf2d

---

## <h2 id="p1p2"><center>Однородное вероятностное пространство</center></h2>

==Опр.== **Однородное [[#<h3 id="p1p1"><center>Понятие вероятностного пространства</center></h3>|ДВП]] (ОДВП, классическое ДВП) $(\Omega,\ \mathcal{F},\ P)$** - если $\forall A \in \mathcal{F}\ \hookrightarrow P(A) = \frac{|A|}{|\Omega|}$

> [!info] Называют
> $P$ в ОДВП называют *классической вероятностью*.

> [!tip] Все исходы в ОДВП равновероятны
> $$\forall \omega \in \Omega\ :\ P(\omega) = \frac{1}{N}$$

> [!important] Ключевое свойство
> Заметим, что ОДВП **однозначно** задаётся множеством элементарных событий $\Omega$. ОДВП имеет вид $(\Omega,\ 2^{\Omega},\ P(A) = \frac{|A|}{|\Omega|})$

---

## <h2 id="p1p3"><center>Операции над событиями</center></h2>

Пусть $A,\ B \in \mathcal{F}$, тогда:

==Опр.== **Противоположное событие** $\overline{A} = A/\Omega$

==Опр.== $A \cdot B = AB = A \cap B$

==Опр.== $A + B = A \sqcup B$, то есть $\begin{cases} A + B = A \cup B, \\ A \cap B = \emptyset \end{cases}$

1) $\overline{A} = A/\Omega$ $\Rightarrow$ так как $A \subset \Omega$, то $P(\overline{A}) = P(\Omega) - P(A) = 1 - P(A)$ (Проверим: $P(A \sqcup \overline{A}) = P(\Omega) = 1$ - свойство [[#<h3 id="p1p1"><center>Понятие вероятностного пространства</center></h3>|вероятностной меры]] выполняется)

2) $P(A + B) = P(A) + P(B)$ - докажем это: пусть $\{A_i\}_{i \in \mathbb{N}}$ - события т.ч.  $$\begin{cases} A_1 = A \\ A_2 = B \\ \forall i > 2 \hookrightarrow A_i = \emptyset \end{cases}$$
	тогда из 3-го свойства вероятностной меры: $P(\bigsqcup\limits_{i=1}^{\infty} A_i)$ $= P(A \sqcup B)$ $= \sum\limits_{i=1}^{\infty} P(A_i)$ $= P(A) + P(B) + \sum\limits_{i=3}^{\infty} P(A_i)$ $= P(A) + P(B)$, так как начиная с 3-го все события невозможные.

3) $P(A \cup B) = P(A) + P(B) - P(AB)$ - так как $A \cup B = A/(A \cap B) \sqcup (A \cap B) \sqcup B/(A \cap B)$

---
<div style="page-break-after: always;"></div>


## <h2 id="p1p4"><center>Условная вероятность</center></h2>
<h3 id="p1p4p1"><center>Понятие условной вероятности</center></h3>

==Опр.== **Условное событие** *($A$ при условии $B$)* - $A|B = A \cap B$, <u>НО</u> В [[#<h3 id="p1p1"><center>Понятие вероятностного пространства</center></h3>|ДВП]] $(B,\ 2^B,\ P|_{B})$. То есть это событие $A$ с условием того, что событие $B$ уже произошло.

==Опр.== **Условная вероятность** - вероятность условного события.

> [!tip] Геометрический смысл
> При рассмотрении условной вероятности происходит переход из исходного ДВП $(\Omega, \mathcal{F}, P)$ в новое ДВП $(\Omega', \mathcal{F}', P') = (B, 2^B, P|_B)$ 
>
> * **Интуиция:** если событие $B$ случилось, то пространство элементарных исходов сужается: $\Omega \to B$ 
>* Вероятность события $A$ в этой модели изменяется, так как теперь учитываются только те исходы $A$, которые попали в $B$, то есть происходит замена $A \to AB$ 

### Формула условной вероятности
$$
P(A|B) = \frac{P'(A)}{P'(\Omega')} = \frac{P(A \cap B)}{P(\Omega')} = \frac{P(AB)}{P(B)}
$$

> [!NOTE] Польза
> То есть для расчёта условной вероятности не обязательно явным образом переходить в новое ДВП, можно работать со старым с помощью формулы выше.

> [!example] Пример
> Пусть $P(A) = p$ - вероятность того, что письмо лежит в столе с 5 ящиками. Мы открыли первые 4 ящика и там письма не оказалось (событие $B$). Условная вероятность того, что письмо в 5-м ящике, вычисляется как:
> $$P(A|B) = \frac{P(A_5)}{P(\bar{A}) + P(A_5)} = \frac{p/5}{1 - p + p/5} = \frac{p}{5 - 4p}$$
> При $p \in (0, 1)$ выполняется условие $P(A) > P(A|B) > P(A_5)$, где $P(A_5)$ - изначальная вероятность нахождения письма в конкретном ящике.

---

<h3 id="p1p4p2"><center>Полная вероятность</center></h3>

==Опр.== $\{B_k\}_{k=1}^n$ - **разбиение** $\Omega$, если $\begin{cases} \forall k \in \overline{1,n} \hookrightarrow B_k \subset \Omega, \\ \bigsqcup\limits_{k=1}^n B_k = \Omega \end{cases}$ ^3b3ad7

- *Замечание*: в определении $n \in \mathbb{N} \cup \{\mathbb{N}\}$


### Формула полной вероятности
Пусть $\{B_k\}_{k=1}^n$ - **разбиение** $\Omega$ в ДВП $(\Omega,\ \mathcal{F},\ P)$, тогда $$\forall A \in \mathcal{F} \hookrightarrow P(A) = \sum\limits_{k=1}^nP(A|B_k)\cdot P(B_k)$$
#### Доказательство
$P(A) =$ $P(A \cdot \Omega) =$ $P(A \cdot \bigsqcup\limits_{k=1}^n B_k) =$ \[Поскольку $\{B_k\}_{k=1}^n$ попарно не пересекаются\] $= \sum\limits_{k=1}^n P(A \cdot B_k) =$ \[Из формулы условной вероятности\] $= \sum\limits_{k=1}^nP(A|B_k)\cdot P(B_k)$.

### Формула Байеса
$$P(B | A) = \frac{P(A | B) \cdot P(B)}{P(A)}$$
#### Доказательство.
Из формул условной вероятности: $\begin{cases} P(A | B) = \frac{P(AB)}{P(B)} \\ P(B | A) = \frac{P(BA)}{P(A)} \end{cases}$ $\Longrightarrow$ из первой формулы выразим $P(AB)$ и подставим во вторую.

---

<h3 id="p1p4p3"><center>Задача Монти Холла</center></h3>

- Данная задача показывает, как формулы условной вероятности решают неинтуитивные проблемы.

![[Pasted image 20251115220752.png]]


> [!quote] *Формулировка задачи*
><p align="justify">Вы - участник телешоу. Перед вами три двери, за двумя из которых велосипеды, а за одной - автомобиль. Вам необходимо выбрать дверь, приз за которой вы получите. Вы, естественно, хотите выиграть автомобиль. После того, как вы выбрали дверь, ведущий открывает другую дверь, за которой оказался велосипед, и даёт вам возможность изменить выбор двери. Стоит ли менять выбор?</p>

#### Решение.

Введём ОДВП, в котором элементарные события - пары $(d,\ f)$, где $d$ - выбранная дверь, а $f$ - оказался ли за ней автомобиль. Пусть события $A = \{(d,\ f)\ |\ f = 1\}$, а $B_i = \{(i, f)\}$.

Пусть мы выбрали дверь с номером $i \in \overline{1,3}$, тогда по формуле Байеса $P(B_i | A) = \frac{P(A | B_i) \cdot P(B_i)}{P(A)} =$ \[по формуле полной вероятности\] $= \frac{P(A | B_i) \cdot P(B_i)}{P(A|B_1) \cdot P(B_1) + P(A|B_2) \cdot P(B_2) + P(A|B_3) \cdot P(B_3)} =$ \[в силу однородности ВП $P(B_i) =$ $P(B_1) =$ $P(B_2) =$ $P(B_3)$\] $= \frac{P(A | B_i)}{P(A|B_1) + P(A|B_2) + P(A|B_3)} =$ \[опять же, из однородности ВП\] $= \frac{1}{3}$. 
Заметим, что $P(\overline{B_i|A}) =$ $P(\overline{B_i}|A) =$ $1 - P(B_i|A) = \frac{2}{3}$ - то есть вероятность, что автомобиль не за изначально выбранной дверью в два раза больше, чем вероятность, что он там. Изменив свой выбор мы увеличим шансы на успех вдвое.

**Ответ**: ДА, стоит поменять выбор.

---

## <h2 id="p1p5"><center>Зависимость событий</center></h2>

==Опр.== **События $A$ и $B$ - независимые** $\Longleftrightarrow$ $P(AB) = P(A) \cdot P(B)$

> [!warning] Важно
> Про зависимость и независимость событий можно говорить тогда и только тогда, когда эти события принадлежат одному [[#<h3 id="p1p1"><center>Понятие вероятностного пространства</center></h3>|ВП]]!

> [!NOTE] Заметим, что
> невозможные и достоверные события независимы с любым другим событием.

### ==Утв.== Если $P(B) > 0$, то $A$ и $B$ - независимые $\Leftrightarrow$ $P(A|B) = P(A)$
- Доказательство прямо следует из [[#<h3 id="p1p4"><center>Условная вероятность</center></h3>|формулы условной вероятности]].

### *Геометрической представление*: события $A$ и $B$ - независимые, если $\exists$ СК в их ВП т.ч. эти события в ней ЛНЗ

### Множества событий

==Опр.== $\{A_i\}_{i=1}^n$ - **попарно независимые**  $\forall A, B \in \{A_i\}_{i=1}^n\ \hookrightarrow$ $A$ и $B$ - независимые

==Опр.== $\{A_i\}_{i=1}^n$ - **независимые в совокупности** $\Leftrightarrow$ $\forall \{A_{i_j}\}_{j=1}^m \subseteq \{A_i\}_{i=1}^n\ \hookrightarrow$ $P(\bigcap\limits_{j = 1}^m A_{i_j}) = \prod\limits_{j = 1}^m P(A_{i_j})$

### Из независимости в совокупности, очевидно, следует попарная независимость. Обратное неверно. Контрпример (Тетраэдр Бернштейна):

![[Pasted image 20251115215138.png]]
Пусть есть тетраэдр, три грани которого покрашены в красный, синий и зелёный цвета соответственно, а четвёртая содержит каждый из трёх цветов. Случайно выбирается одна из его граней (например, в результате "броска"). Элементарными событиями будут выступать множества цветов, которые есть на выпавшей грани, а ДВП будем считать классическим. $P(К) = P(С) = P(З) = \frac{1}{2}$ - в силу однородности составленного пространства. $P(КС) = P(К)P(С)$, НО $P(КСЗ) = \frac{1}{4} \neq \frac{1}{8} = P(К)P(С)P(З)$.

---

### Независимые испытания

- Одно испытание происходит в одном ВП. Если есть несколько испытаний, то они принадлежат разным ВП и говорить о независимости событий, которые связаны с этими испытаниями, просто некорректно в силу замечаний выше. Поэтому определяют новое ВП, в котором эти события уже можно сравнивать.

Пусть $\{(\Omega_i, 2^{\Omega_i}, P_i)\}_{i=1}^n$ - различные ДВП, тогда ДВП серии независимых испытаний из этих ДВП будем считать ДВП = $(\widehat{\Omega}, 2^{\widehat{\Omega}}, \widehat{P})$, где 
1) $\widehat{\Omega} = \Omega_1 \times \dots \times \Omega_n$ (то есть $\forall \widehat{\omega} \in \widehat{\Omega}\ :\ \widehat{\omega} = (\omega_1 \in \Omega_1, \dots, \omega_n \in \Omega_n)$)
2) $\widehat{P}(\widehat{\omega}) = \prod\limits_{i=1}^n P(\omega_i)$
3) $\forall k \in \overline{1,n}\ \forall A \in \Omega_k\ :\ \widehat{A} = \{\widehat{\omega} \in \widehat{\Omega}\ |\ \omega_k \in A\}$

### ==Утв.== $\forall A \in \Omega_i\ \forall B \in \Omega_j\ :\ \begin{cases} P_i(A) = \widehat{P}(\widehat{A}), \\ \widehat{P}(\widehat{A} \widehat{B}) = \widehat{P}(\widehat{A}) \widehat{P}(\widehat{B}) \end{cases}$
#### Доказательство.
1) Обозначим $P \equiv \widehat{P}$. боо $i = 1$. $P(\widehat{A}) = \sum\limits_{\widehat{\omega_j} \in \widehat{A}}\ \prod\limits_{i=1}^n P_i(\omega_{j_i}) =$ $\sum\limits_{\omega_{j_1} \in A}\ \sum\limits_{\omega_{j_2} \in \Omega_2}\ \dots \sum\limits_{\omega_{j_n} \in \Omega_n}\ \prod\limits_{i=1}^n P_i(\omega_{i_j}) =$ $(\sum\limits_{\omega_{j_1} \in A} P_1(\omega_{j_1}))\ (\prod\limits_{i=2}^n \sum\limits_{\omega_{j_{i}} \in \Omega_i}\ P_i(\omega_{j_i}))$ $= (\sum\limits_{\omega_{j_1} \in A} P_1(\omega_{j_1})) \cdot 1$ = $P_1(A)$
2) Аналогично пункту 1, но вынесем сумму при $\Omega_j$ тоже.

---
<div style="page-break-after: always;"></div>


## <h2 id="p1p6"><center>Дискретные случайные величины</center></h2>
<h3 id="p1p6p1"><center>Понятие дискретной случайной величины</center></h3>`

==Опр.== **Дискретная случайная величина (Дискретная СВ, ДСВ)** - всюдуопределённая функция вида $\xi : \Omega \to \mathbb{R}$

==Опр.== **Индикатор** *(события $A$)* - СВ вида $\mathbb{1}_A(\omega) = \begin{cases} 1,\ \omega \in A\\ 0,\ \omega \not\in A \end{cases}$

> [!warning] Важно
> ДСВ задаётся для конкретного [[#<h1 id="p1"><center>Дискретное вероятностное пространство</center></h1>|ДВП]], без заданного [[#<h1 id="p1"><center>Дискретное вероятностное пространство</center></h1>|ДВП]] ДСВ неопределена.

> [!info] Если ДВП не задано явно
> <p align="justify">Если ДВП не задано явно, но используется множество элементарных событий возле ДСВ, то считается, что используется классическое ДВП над данным множеством элементарных событий.</p>

#### Обозначения

- Пусть $\xi$ - ДСВ. Запись вида $\{\xi \circ A\}$ будет означать $\{\omega \in \Omega\ |\ \xi(\omega) \circ A(\omega)\}$
- Пусть $\xi$ и $\eta$ - ДСВ. Запись вида $\{\xi \circ_1 A,\ \eta \circ_2 B\}$ будет означать $\{\omega \in \Omega\ |\ \xi(\omega) \circ_1 A(\omega)\ \wedge\ \eta(\omega) \circ_2 B(\omega)\}$
- Пусть $\xi$ - ДСВ. Запись вида $P(\xi \circ A)$ будет означать $P(\{\xi \circ A\})$
- Пусть $\xi$ и $\eta$ - ДСВ. Запись вида $P(\xi \circ_1 A,\ \eta \circ_2 B)$ будет означать $P(\{\xi \circ_1 A,\ \eta \circ_2 B\})$

Примеры:
1) $P(\xi = x)$ $=$ $P(\{\omega \in \Omega\ |\ \xi(\omega) = x\})$
2) $P(\xi < x)$ $=$ $P(\{\omega \in \Omega\ |\ \xi(\omega) < x\})$
3) Пусть $\eta$ - ДСВ, тогда $P(\xi = \eta)$ $=$ $P(\{\omega \in \Omega\ |\ \xi(\omega) = \eta{\omega}\})$
4) Пусть $\eta$ - ДСВ, тогда $P(\xi \leq x)$ $=$ $P(\{\omega \in \Omega\ |\ \xi(\omega) \leq \eta(\omega)\})$
5)  $P(\xi \in A)$ $=$ $P(\{\omega \in \Omega\ |\ \xi(\omega) \in A\})$
6) $P(\xi = x,\ \eta \leq y)$ $=$ $P(\{\omega \in \Omega\ |\ \xi(\omega) = x\ \wedge\ \eta(\omega) \leq y\})$

> [!success] Дискретность
> Множество значений любой ДСВ не более чем счётно.

Пусть $A^{\xi}(x) = \{\xi = x\}$, тогда в силу дискретности ВП и соответствующей СВ множество $\{x\ |\ A^{\xi}(x) \neq \emptyset\}$ не более чем счётно. Занумеруем его элементы в порядке возрастания, и тогда определим $A_k^{\xi} = A^{\xi}(x_k)$ в данной нумерации. 

==Опр.== $P_{\xi}(k) = P(\xi = x_k)$

==Опр.== $\{A_k^{\xi}\}$ - [[#<h2 id="p1p4"><center>Условная вероятность</center></h2>|разбиение]], порождённое $\xi$.

> [!info] Таблица распределения ДСВ
> Конечные ДСВ удобно представлять в виде таблицы, где в первой строке указаны значения этой ДСВ, а во второй - их вероятности:
> 

| $x_1$ | $x_2$ | $\dots$ | $x_n$ |
| ----- | ----- | ------- | ----- |
| $p_1$ | $p_2$ | $\dots$ | $p_n$ |

### Теорема о простоте ДСВ
$$\forall \xi\ \exists \{A_i\}_{i=1}^{\infty} \subset \mathcal{F}\ \exists \{c_i\}_{i=1}^{\infty} \subset{\mathbb{R}}\ :\ \xi = \sum\limits_{k=1}^{\infty}\mathbb{1}_{A_k} \cdot c_k$$
#### Доказательство.
$\forall \omega \in \Omega\ \exists! k\ :\ \omega \in A_k^{\xi}$ $\Longrightarrow$ $\xi|_{A_k^{\xi}} \equiv x_k$, $\Longrightarrow$ $\xi =$ $\xi|_{A_k^{\xi}} + \xi|_{\overline{A_k^{\xi}}} =$ $\mathbb{1}_{A_k^{\xi}} \cdot x_k + \xi|_{\overline{A_k^{\xi}}}$, а так как $\{A_k^{\xi}\}$ попарно не пересекаются, то $\forall i \neq k\ :$ $(\xi|_{\overline{A_k^{\xi}}})|_{A_i^{\xi}} \equiv \xi|_{A_k^{\xi}}$. 
Тогда искомое представление $\xi$ строится индуктивно по множеству $\{A_k^{\xi}\}$ и получаем $\{A_i\}_{i=1}^{\infty} = \{A_k^{\xi}\}$ (Если $\{A_k^{\xi}\}$ конечно, то его можно дополнить пустыми множествами) и $\{c_i\}_{i=1}^{\infty} = \{x_k\}$ (можно дополнить нулями).

---

<h3 id="p1p6p2"><center>Схема Бернулли</center></h3>

==Опр.== **Испытание Бернулли** - это эксперимент с двумя исходами: «успех» с вероятностью $p$ и «неудача» с вероятностью $q$

==Опр.== **Схема Бернулли** - это серия из $n$ независимых испытаний Бернулли с неизменной вероятностью успеха $p$

Испытание Бернулли можно описать в ДВП, в котором всего два элементарных события. боо обозначим эти события 0 и 1, то есть $\Omega = B = \{0,\ 1\}$. Пусть $P(\{1\}) = p$, а $P(\{0\}) = q$, тогда в силу свойств вероятности $p + q = 1$.

Рассмотрим [[#Независимые испытания|серию из n испытаний]] Бернулли, то есть схему Бернулли. Её можно описать в ДВП $(\widehat{\Omega}, 2^{\widehat{\Omega}}, \widehat{P})$, порождённом данной серией испытаний.

### Характеристики схемы Бернулли

* Пространство исходов $\hat{\Omega}$ состоит из векторов $\omega = (\omega_1, \dots, \omega_n)$, где каждый $\omega_i \in \{0, 1\}$
* Вероятность конкретного исхода, содержащего ровно $k$ успехов и $n-k$ неудач, вычисляется по формуле:$$P(\omega) = p^k q^{n-k}$$
- **Формула Бернулли**: вероятность того, что в $n$ испытаниях наступит ровно $k$ успехов, равна:$$P_n(k) = C_n^k p^k q^{n-k}$$
Обоснование: $\{\text{Число успехов в испытаниях} = k\}$ $\equiv$ $\{\{i_j\}_{j=1}^n\ |\ \forall j, j' \in \overline{1, k}\ :\ (j \neq j') \rightarrow (i_j \neq i_{j'}),\ \omega_{i_j} = 1;\ \forall j \in \overline{k+1, n}\ :\ \omega_{i_j} = 0\}$) и применяем вероятность конкретного исхода.

> [!NOTE] Связь с ДСВ
> Количество успехов в схеме Бернулли является дискретной случайной величиной, принимающей значения $\overline{0,n}$. Сумма вероятностей по всем $k$ равна $(p+q)^n = 1^n = 1$, что подтверждает корректность модели.

---

<h3 id="p1p6p3"><center>Матожидание ДСВ</center></h3>

==Опр.== **Математическое ожидание (матожидание) ДСВ $\xi$** - $\mathbb{E}\xi = \sum\limits_{\omega \in \Omega} P(\omega) \cdot \xi(\omega)$, причём данный ряд *сходится абсолютно*. (Если ряд не сходится или сходится условно, то матожидания не существует)

### Геометрический смысл матожидания: $\mathbb{E}\xi$ - центр масс взвешенных точек $\{x_k\}$

### Эквивалентное определение матожидания
$$\mathbb{E}\xi = \sum\limits_{k=1}^{m}x_k \cdot P_{\xi}(k)$$где $m$ - мощность разбиения, порождённого $\xi$.

#### Доказательство.
$\mathbb{E}\xi =$ $\sum\limits_{\omega \in \Omega} P(\omega) \cdot \xi(\omega) =$ $\sum\limits_{k=1}^{m} \sum\limits_{\omega \in A_k^{\xi}} P(\omega) \cdot \xi(\omega) =$ \[т.к. $\forall \omega \in A_k^{\xi}\ :\ \xi(\omega) = x_k$\] $= \sum\limits_{k=1}^{m} x_k \cdot \sum\limits_{\omega \in A_k^{\xi}} P(\omega)$ $= \sum\limits_{k=1}^{m}x_k \cdot P_{\xi}(k)$

### Свойства матожидания

1) Матожидание - функционал.
2) Матожидание линейно. Пространство всех ДСВ над данным ДВП тоже линейно.
3) $\forall \xi \geq 0\ :\ E\xi \geq 0$
4) $\xi \geq \eta\ \Longrightarrow\ \mathbb{E}\xi \geq \mathbb{E}\eta$ - монотонность
5) $\mathbb{E}(\xi\eta) \leq \sqrt{\mathbb{E}\xi^2 \cdot \mathbb{E}\eta^2}$ - неравенство КБШ. (Причём $\mathbb{E}(\xi\eta) = \sqrt{\mathbb{E}\xi^2 \cdot \mathbb{E}\eta^2}$ $\Leftrightarrow$ $\exists c = const,\ \eta = c \cdot \xi$)

#### Доказательство.
1) Функционал - функция, определённая на множестве функций. Матожидание - функционал по определению.
2) То, что пространство всех ДСВ над данным ДВП линейно проверяется через аксиомы и [[#Теорема о простоте ДСВ|простоту ДСВ]]. Пусть $\xi, \eta$ - ДСВ над одним ДВП, тогда 
	1) $\mathbb{E}(\xi + \eta) =$ $\sum\limits_{\omega \in \Omega} P(\omega) \cdot (\xi + \eta)(\omega) =$ $\sum\limits_{\omega \in \Omega} P(\omega) \cdot \xi(\omega) + \sum\limits_{\omega \in \Omega} P(\omega) \cdot \eta(\omega)$ $= E\xi + E\eta$
	2) $\forall \alpha \in \mathbb{R}\ :\ \sum\limits_{\omega \in \Omega} \mathbb{E}(\alpha\xi) =$ $P(\omega) \cdot (\alpha\xi)(\omega) =$ $\alpha\sum\limits_{\omega \in \Omega} P(\omega) \cdot \xi(\omega)$ $= \alpha E\xi$
	Таким образом, матожидание линейно.
3) Очевидно из того соображения, что вероятность неотрицательна, а сумма и произведение неотрицательных функций неотрицательны.
4) $\xi  \geq \eta$ $\Rightarrow$ $(\xi - \eta) \geq 0$ $\Rightarrow$ $\mathbb{E}(\xi - \eta) = \mathbb{E}\xi - \mathbb{E}\eta \geq 0$ $\Rightarrow$ $\mathbb{E}\xi \geq \mathbb{E}\eta$
5) Пусть $f(x, y) = \mathbb{E}(xy)$, тогда из пункта 2 следует, что $f$ линейна по обоим аргументам, $f(x, y) = f(y, x)$, из пунктов 3 и 4 следует, что $f$ положительно определена ($f(\xi, \xi) = 0 \Leftrightarrow \xi \equiv 0$). Получается, что $f$ - положительно определённая билинейная форма, а потому может быть использована в качестве скалярного произведения в ЛП всех ДСВ над одним ДВП, а для скалярного произведения КБШ было уже доказано.

---

<h3 id="p1p6p4"><center>Дисперсия ДСВ</center></h3>

==Опр.== **Дисперсия ДСВ $\xi$** - функционал вида $\mathbb{D}\xi =$ $\mathbb{E}(\xi - \mathbb{E}\xi)^2 =$ $\mathbb{E}\xi^2 - (\mathbb{E}\xi)^2$

### Свойства дисперсии

1) $\mathbb{D}\xi \geq 0$
2) $\mathbb{D}\xi = 0 \Leftrightarrow \xi = const$
3) $\forall c = const\ :\ \mathbb{D}(c\xi) = c^2 \mathbb{D}\xi$
4) Дисперсия НЕ линейна 

#### Доказательство.
1) $(\xi - \mathbb{E}\xi)^2 \geq 0$ $\Rightarrow$ по монотонности матожидания $\mathbb{D}\xi =$ $\mathbb{E}(\xi - \mathbb{E}\xi)^2$ $\geq 0$
2) $\mathbb{D}\xi =$ $\mathbb{E}(\xi - \mathbb{E}\xi)^2$ $= 0$ $\Leftrightarrow$ $\xi =$ $\mathbb{E}\xi = const$
3) $\mathbb{D}(c\xi) =$ $\mathbb{E}(c\xi - \mathbb{E}(c\xi))^2 =$ $\mathbb{E}(c(\xi - \mathbb{E}\xi))^2 =$ $\mathbb{E}c^2(\xi - \mathbb{E}\xi)^2 =$ $c^2 \mathbb{D}\xi$
4) Контрпример: $\eta = 2\xi$

---

<h3 id="p1p6p5"><center>Дисперсия ДСВ</center></h3>

==Опр.== **Центровка СВ** $\xi^c = \xi - \mathbb{E}\xi$

==Опр.== **Центрированная СВ** - СВ $\xi$, для которой верно $\xi = \xi^c$

==Опр.== **Нормировка СВ** $\xi^n = \frac{\xi}{\sqrt{\mathbb{D}\xi}}$

==Опр.== **Нормированная СВ** - СВ $\xi$, для которой верно $\xi = \xi^n$

### Свойства
1) $\mathbb{E}\xi^c = 0$
2) $\mathbb{D}\xi = \mathbb{D}\xi^c$
3) $\mathbb{D}\xi^n = 1$

#### Доказательство.
1) $\mathbb{E}\xi^c =$ $\mathbb{E}(\xi - \mathbb{E}\xi) =$ $\mathbb{E}\xi - \mathbb{E}\mathbb{E}\xi =$ \[т.к. $\mathbb{E}\xi = const$\] $= \mathbb{E}\xi - \mathbb{E}\xi$ $= 0$
2) $\mathbb{D}\xi^c =$ $\mathbb{E}(\xi^c - \mathbb{E}\xi^c)^2 =$ $\mathbb{E}(\xi^c)^2 = \mathbb{E}(\xi - \mathbb{E}\xi)^2$ $= \mathbb{D}\xi$
3) $\mathbb{D}\xi^n =$ $\mathbb{E}(\xi^n - \mathbb{E}\xi^n)^2 =$ $\mathbb{E}(\frac{\xi}{\sqrt{\mathbb{D}\xi}} - \mathbb{E}\frac{\xi}{\sqrt{\mathbb{D}\xi}})^2 =$ $\frac{1}{\mathbb{D}\xi}\mathbb{E}(\xi^c-\mathbb{E}\xi^c)^2$ $= \frac{\mathbb{D}\xi}{\mathbb{D}\xi} = 1$ 

---

<h3 id="p1p6p6"><center>Независимость случайных величин</center></h3>

==Опр.== **Независимые ДСВ** *($\xi$ и $\eta$)* $\Longleftrightarrow$ $\forall x \in \mathbb{R}\ \forall y \in \mathbb{R}\ :\ P(\xi = x,\ \eta = y)$ $= P(\xi = x) \cdot P(\eta = y)$

> [!warning] Важно
> ДСВ всегда определена на конкретном вероятностном пространстве. Говорить о независимости СВ из разных экспериментов без построения прямого произведения их пространств некорректно.

### Критерий независимости индикаторов
$$A\ \text{и}\ B\ -\ \text{независимые}\ \Longleftrightarrow \mathbb{1}_A\ \text{и}\ \mathbb{1}_B\ -\ \text{независимые}$$

#### Доказательство
##### Необходимость:
Пусть $A$, $B$ $\in \mathcal{F}$ независимы. Проверим, что $\forall x, y \in \{0, 1\}$ выполняется:$$
P(\mathbb{1}_A = x,\ \mathbb{1}_B = y) = P(\mathbb{1}_A = x) \cdot P(\mathbb{1}_B = y).
$$Рассмотрим все 4 возможные пары $(x, y)$:
1.  $x=1, y=1$: $\{\mathbb{1}_A=1, \mathbb{1}_B=1\} = A \cap B$.  
    $P(A \cap B) =$ $P(A)P(B) =$ $P(\mathbb{1}_A=1) \cdot P(\mathbb{1}_B=1)$.
2.  $x=1, y=0$: $\{\mathbb{1}_A=1, \mathbb{1}_B=0\} = A \cap \overline{B}$.  
    $P(A \cap \overline{B}) =$ $P(A) - P(A \cap B) = P(A) - P(A)P(B) =$ $P(A)(1-P(B)) =$ $P(\mathbb{1}_A=1) \cdot P(\mathbb{1}_B=0)$.
3.  $x=0, y=1$: $\{\mathbb{1}_A=0, \mathbb{1}_B=1\} = \overline{A} \cap B$.  
    Аналогично: $P(\overline{A} \cap B) =$ $(1-P(A))P(B) =$ $P(\mathbb{1}_A=0) \cdot P(\mathbb{1}_B=1)$.
4.  $x=0, y=0$: $\{\mathbb{1}_A=0, \mathbb{1}_B=0\} = \overline{A} \cap \overline{B}$.  
    $P(\overline{A} \cap \overline{B}) =$ $1 - P(A \cup B) =$ $1 - [P(A)+P(B)-P(A\cap B)] =$ $1 - P(A) - P(B) + P(A)P(B) =$ $(1-P(A))(1-P(B)) =$ $P(\mathbb{1}_A=0) \cdot P(\mathbb{1}_B=0)$.
Во всех случаях равенство выполняется. Следовательно, $\mathbb{1}_A$ и $\mathbb{1}_B$ независимы.

##### Достаточность:
Пусть СВ $\mathbb{1}_A$ и $\mathbb{1}_B$ независимы. Тогда, в частности, для $x=1$ и $y=1$ должно выполняться равенство из определения независимости:$$
P(\mathbb{1}_A = 1,\ \mathbb{1}_B = 1) = P(\mathbb{1}_A = 1) \cdot P(\mathbb{1}_B = 1).
$$Но это равенство в точности означает:$$
P(A \cap B) = P(A) \cdot P(B),
$$что и является определением независимости событий $A$ и $B$.

### Теорема о совместном матожидании независимых ДСВ

Пусть $\xi$ и $\eta$ - независимые ДСВ, у которых существует конечное [[#Эквивалентное определение матожидания|матожидание]], тогда$$\mathbb{E}(\xi\eta) = (\mathbb{E}\xi)(\mathbb{E}\eta)$$
#### Доказательство
$\mathbb{E}(\xi\eta) =$ $\sum\limits_{i=1}^n \sum\limits_{j=1}^m x_i y_j\ P(\xi = x_i,\ \eta = y_j) =$ $(\sum\limits_{i=1}^n x_i\ P(\xi = x_i))\cdot(\sum\limits_{j=1}^m y_j\ P(\eta = y_j))$ $= (\mathbb{E}\xi)(\mathbb{E}\eta)$, где $\{x_i\}_{i=1}^n$ и $\{y_j\}_{j=1}^m$ - коэффициенты $\xi$ и $\eta$ соотв. из [[#Теорема о простоте ДСВ|теоремы о простоте ДСВ]]

---
<div style="page-break-after: always;"></div>



# <h1 id="p2"><center>Стохастическое вероятностное пространство</center></h1>
## <h2 id="p2p1"><center>Аксиоматика Колмогорова</center></h2>

<p align="justify">При описании экспериментов с бесконечным несчётным количеством исходов возникают трудности, не позволяющие использовать простую дискретную модель:</p>

1) НЕЛЬЗЯ построить ВП, просто задав вероятности каждого ЭИ, так как их континуум. 
2) НЕЛЬЗЯ считать событием любое подмножество пространства исходов, поскольку некоторые из них могут быть неизмеримы. Следовательно, нам нужно выбрать класс "хороших" подмножеств пространства ЭИ.

<p align="justify">Расширим понятия вероятностной модели и вероятностного пространства на более чем счётные множества ЭИ. Определения вероятностной модели, ЭИ и вероятности остаются теми же. Переопределим остальные понятия.</p>

> [!important] Напоминание (**Основная лемма**)
> Для любого семейства подмножеств $\mathcal{F}$ существует единственная минимальная $\sigma$-алгебра $\sigma(\mathcal{F})$, содержащая это семейство

==Опр.== **Пространство элементарных исходов**  $\Omega = \{\omega\}$ - (непустое, не более чем континуум) множество *элементарных событий*.

==Опр.== **Класс событий** $\mathcal{F} \subseteq 2^{\Omega}$ такой, что он является сигма-алгеброй подмножеств $\Omega$.

> [!success] Сохранение определённости событий
> <p align="justify">Заметим, что вероятностная мера может быть посчитана для любого события. Если бы мы взяли неизмеримые подмножества как события, то вероятность потеряла бы свойство всюдуопределённости в рамках модели.</p>

==Опр.== **Невозможное событие** ($A$) - $A = \emptyset$.

==Опр.== **Достоверное событие** ($A$) - $A = \Omega$.

==Опр.== **Вероятностное пространство (ВП)** - вероятностная модель вида $(\Omega,\ \mathcal{F},\ P)$. ^db6c11

---

## <h2 id="p2p02"><center>Геометрическая вероятность</center></h2>

==Опр.== **Геометрическая вероятность** - это теоретико-вероятностная модель, в которой пространство элементарных исходов $\Omega$ представляет собой измеримое подмножество $n$-мерного евклидова пространства ($\Omega \subset \mathbb{R}^n$), имеющее конечную и положительную меру Лебега ($0 < \mu(\Omega) < \infty$).

В этой модели под событиями понимаются измеримые по Лебегу подмножества $\Omega$. Вероятность события определяется как отношение меры этого события к мере всего пространства:
$$P(A) = \frac{\mu(A)}{\mu(\Omega)}$$

> [!tip] По-простому
> Здесь $\mu$ может означать в простом смысле, например, длину на прямой или кривой, площадь на плоскости или объем в пространстве.

> [!example] Пример: выбор точек из отрезка
> Пусть из отрезка $[0; 1]$ случайно и независимо выбираются три точки $x_1, x_2, x_3$. Событие $A$ = «третья точка оказалась между первыми двумя». Пространство $\Omega$ - это куб $[0; 1]^3$ с мерой $1$. Расчёт через интеграл показывает, что $\mu(A) = \frac{1}{3}$, следовательно, $P(A) = \frac{1}{3}$

### Корректность геометрической модели

- Функция $P(A) = \frac{\mu(A)}{\mu(\Omega)}$ является вероятностной мерой, удовлетворяющей аксиомам Колмогорова. Геометрическая модель - частный случай вероятностной модели.

#### Доказательство

1.  **Неотрицательность**: Поскольку мера Лебега подмножества всегда неотрицательна и $\mu(\Omega) > 0$, то $P(A) \ge 0$
2.  **Нормировка**: $P(\Omega) = \frac{\mu(\Omega)}{\mu(\Omega)} = 1$
3.  **$\sigma$-аддитивность**: Пусть $\{A_k\}$ - последовательность попарно непересекающихся измеримых множеств. В силу свойства счётной аддитивности меры Лебега имеем:
$$P\left(\bigsqcup_{k=1}^{\infty} A_k\right) = \frac{\mu(\bigsqcup A_k)}{\mu(\Omega)} = \frac{\sum \mu(A_k)}{\mu(\Omega)} = \sum_{k=1}^{\infty} P(A_k)$$

---

## <h3 id="p2p02p1"><center>Парадокс Бертрана</center></h3>

==Опр.== **Парадокс Бертрана** - это классическая проблема теории вероятностей, демонстрирующая, что результат вычисления геометрической вероятности напрямую зависит от способа введения вероятностной модели (способа «случайного выбора»)

> [!quote] Формулировка задачи
> В круге радиуса $R$ случайно выбирается хорда. Требуется найти вероятность того, что длина этой хорды будет больше стороны правильного треугольника, вписанного в этот круг ($L > \sqrt{3}R$)

- Существует множество способов решения, рассмотрим три основных из них:

### 1. Метод случайного выбора середины хорды

Хорда однозначно задается своей серединой. Чтобы хорда была длиннее стороны треугольника, её середина должна лежать внутри вписанной окружности с радиусом $R/2$.
*   Пространство $\Omega$ - круг радиуса $R$.
*   Событие $A$ - круг радиуса $R/2$.
$$P(A) = \frac{\mu_2(A)}{\mu_2(\Omega)} = \frac{\pi (R/2)^2}{\pi R^2} = \frac{1}{4}$$

### 2. Метод случайного выбора расстояния до центра

Хорда задается расстоянием $h$ от центра круга. В силу симметрии круга этого достаточно. Хорда длиннее стороны треугольника, если расстояние $h$ меньше апофемы треугольника, которая равна $R/2$.
*   Пространство $\Omega$ - отрезок $[0; R]$ (возможные расстояния).
*   Событие $A$ - отрезок $[0; R/2]$.
$$P(A) = \frac{\mu_1(A)}{\mu_1(\Omega)} = \frac{R/2}{R} = \frac{1}{2}$$

### 3. Метод случайного выбора точки на окружности и угла

Фиксируется одна точка хорды на окружности (в силу симметрии боо это верхняя точка окружности). Направление хорды однозначно задаётся углом $\alpha$ между хордой и касательной. Подходящие хорды образуют углы в диапазоне $(\frac{\pi}{3}; \frac{2\pi}{3})$.
*   Пространство $\Omega$ - интервал углов $(0; \pi)$.
*   Событие $A$ - интервал $(\frac{\pi}{3}; \frac{2\pi}{3})$.
$$P(A) = \frac{\mu_1(A)}{\mu_1(\Omega)} = \frac{\pi/3}{\pi} = \frac{1}{3}$$

> [!warning] ВЫВОД:
> <p align="justify">Пока вероятностная модель не задана явным образом (то есть не определён способ выбора исхода), говорить о конкретном значении вероятности в стохастическом случае некорректно. Разный выбор модели в одной и той же ситуации может давать разные ответы.</p>

---
<div style="page-break-after: always;"></div>


## <h2 id="p2p2"><center>Стохастические случайные величины</center></h2>
<h3 id="p2p2p1"><center>Понятие случайной величины</center></h3>

==Опр.== **Случайная величина (СВ)** - всюдуопределённая функция вида $\xi : \Omega \to \mathbb{R}$ т.ч.
1) $\forall c \in \mathbb{R}\ :\ \{\omega\in \Omega\ |\ \xi(\omega) \leq c\} \in \mathcal{F}$
ИЛИ
2) $\forall B \in \mathcal{B}(\mathbb{R})\ :\ \xi^{-1}(B) \in \mathcal{F}$

**То есть мы накладываем на СВ условие измеримости**: для $\forall$ борелевского множества $B \in \mathcal{B}(\mathbb{R})$ его прообраз принадлежал сигма-алгебре событий: $\xi^{-1}(B) \in \mathcal{F}$. Практически это означает, что события вида $\{\omega \mid \xi(\omega) \le x\}$ должны иметь определённую вероятность для $\forall x \in \mathbb{R}$

> [!tip] Связь с ДСВ
> Заметим, что индикатор любого события и индикатор события, умноженный на константу являются СВ, а также ЛК нескольких индикаторов событий, тоже. Следовательно, [[#<h2 id="p1p6"><center>Дискретные случайные величины</center></h2>|ДСВ]] - частный случай стохастической СВ.

> [!info] Обозначения
> Аналогично ДСВ будем использовать те же [[#<h2 id="p1p6"><center>Дискретные случайные величины</center></h2>|обозначения]] и отметим, что СВ всегда задаётся в конкретном [[#<h2 id="p2p1"><center>Аксиоматика Колмогорова</center></h2>|ВП]] и неразрывно с ним связана.

### Теорема об эквивалентности определений

- Определения 1 и 2 СВ эквивалентны

#### Доказательство

**(2) $\Rightarrow$ (1):** Это прямое следствие. Так как для $\forall c \in \mathbb{R}$ луч $(-\infty; c] \in \mathcal{B}(\mathbb{R})$, то из условия (2) сразу следует, что $\xi^{-1}((-\infty; c]) = \{\omega: \xi(\omega) \leq c\} \in \mathcal{F}$.

**(1) $\Rightarrow$ (2):** 
1) Рассмотрим систему множеств:$$
    \mathcal{G} = \{ B \subset \mathbb{R} \mid \xi^{-1}(B) \in \mathcal{F} \}.
    $$
2) Покажем, что $\mathcal{G}$ является $\sigma$-алгеброй:
    1.  $\varnothing \in \mathcal{G}$, так как $\xi^{-1}(\varnothing) = \varnothing \in \mathcal{F}$.
    2.  Пусть $B \in \mathcal{G}$. Тогда $\xi^{-1}(B) \in \mathcal{F}$. Так как $\mathcal{F}$ - $\sigma$-алгебра, то $(\xi^{-1}(B))^c \in \mathcal{F}$. Но $(\xi^{-1}(B))^c =$ $\xi^{-1}(B^c)$. Следовательно, $\xi^{-1}(B^c) \in \mathcal{F}$, а значит $B^c \in \mathcal{G}$.
    3.  Пусть $\{B_k\}_{k=1}^{\infty} \subset \mathcal{G}$. Тогда $\forall n \in \mathbb{N}:$ $\xi^{-1}(B_n) \in \mathcal{F}$. Так как $\mathcal{F}$ - $\sigma$-алгебра, то $\bigcup_{n=1}^{\infty} \xi^{-1}(B_n) \in \mathcal{F}$. Но $\bigcup_{n=1}^{\infty} \xi^{-1}(B_n) =$ $\xi^{-1}(\bigcup_{n=1}^{\infty} B_n)$. Следовательно, $\xi^{-1}(\bigcup_{n=1}^{\infty} B_n) \in \mathcal{F}$, а значит $\bigcup_{n=1}^{\infty} B_n \in \mathcal{G}$.
	Таким образом, $\mathcal{G}$ - это $\sigma$-алгебра подмножеств $\mathbb{R}$.

3) Покажем, что $\mathcal{G}$ содержит порождающие множества $\mathcal{B}(\mathbb{R})$:
    По условию (1) мы знаем, что для любого $c \in \mathbb{R}$ множество $\{\xi \leq c\} \in \mathcal{F}$. Это в точности означает, что $\xi^{-1}((-\infty; c]) \in \mathcal{F}$, а следовательно, $(-\infty; c] \in \mathcal{G}$. Класс $\mathcal{H} = \{(-\infty;c]\ |\ c \in \mathbb{R}\}$ является порождающим классом для борелевской $\sigma$-алгебры $\mathcal{B}(\mathbb{R})$, поскольку:
	    1. $\forall a \in \mathbb{R}\ :\ (a; +\infty) =$ $(-\infty; a]^c \in \sigma\mathcal{(H)}$
	    2. $\forall a, b \in \mathbb{R}\ :\ (a; b] =$ $(a; +\infty) \cap (-\infty; b] \in \sigma\mathcal{(H)}$
	    3. $\forall a \in \mathbb{R}\ :\ \{a\} =$ $\bigcap\limits_{n=1}^{\infty} (a - \frac{1}{n}; a] \in \sigma\mathcal{(H)}$
	    4. $\forall a, b \in \mathbb{R}\ :\ (a; b) =$ $(a; b] \cap \{a\}^c \in \sigma\mathcal{(H)}$
	    5. $\forall c \in \mathbb{R}\ :\ (-\infty; c) =$ $(-\infty; c] \cap \{c\}^c \in \sigma\mathcal{(H)}$
	    6. По теореме о структуре открытых множеств вещественной прямой и из пунктов 1, 4, 5 получается, что $\forall U \subset \mathbb{R}$ т.ч. $U = int\ U$ выполняется $U \in \sigma\mathcal{(H)}$, т.к. $U$ представима счётным объединением промежутков.
	Получается: $\mathcal{B}(\mathbb{R}) \subset \sigma\mathcal{(H)}$

4) Применяем теорему о порождении $\sigma$-алгебры:
    Мы имеем:
    1.  $\mathcal{G}$ - $\sigma$-алгебра.
    2.  $\mathcal{G}$ содержит все множества вида $(-\infty, c]$.
	Поскольку $\sigma\mathcal{(H)}$ - это *наименьшая* $\sigma$-алгебра, содержащая все $(-\infty, c]$, из этого следует, что $\mathcal{B}(\mathbb{R}) \subset \sigma\mathcal{(H)}$ $\subset \mathcal{G}$, то есть для $\forall B \in \mathcal{B}(\mathbb{R})$ выполнено $\xi^{-1}(B) \in \mathcal{F}$, что и есть условие (2).

### Сохранение СВ под действием измеримого отображения

- Пусть $\xi : \Omega \to \mathbb{R}$ - СВ, а $f : \mathbb{R} \to \mathbb{R}$ - борелевская функция ($\in \mathcal{M}_1$), тогда $\eta = \xi \circ f : \Omega \to \mathbb{R}$ - тоже СВ на том же ВП, что и $\xi$
#### Доказательство

Покажем, что для $\forall$ $B \in \mathcal{B}(\mathbb{R})$ прообраз $\eta^{-1}(B) \in \mathcal{F}$:
1. Рассмотрим произвольное $B \in \mathcal{B}(\mathbb{R})$: $$
    \eta^{-1}(B) = \{\omega \in \Omega : \eta(\omega) \in B\} = \{\omega \in \Omega : f(\xi(\omega)) \in B\}$$
2. Заметим, что $f(\xi(\omega)) \in B$ $\Longleftrightarrow$ $\xi(\omega) \in f^{-1}(B)$, cледовательно: $$
    \eta^{-1}(B) = \{\omega \in \Omega : \xi(\omega) \in f^{-1}(B)\} = \xi^{-1}(f^{-1}(B))$$
3. Поскольку $f$ - борелевская функция, она измерима относительно $\mathcal{B}(\mathbb{R})$. Поэтому для $B \in \mathcal{B}(\mathbb{R})$ её прообраз $f^{-1}(B)$ также является борелевским множеством: $f^{-1}(B) \in \mathcal{B}(\mathbb{R})$.

4. Поскольку $\xi$ - СВ, она измерима относительно $\mathcal{F}$. Значит, для $\forall A \in \mathcal{B}(\mathbb{R})$ (в частности, для $A = f^{-1}(B)$) выполняется $\xi^{-1}(A) \in \mathcal{F}$.
Таким образом, $\forall B \in \mathcal{B}(\mathbb{R})$: $\eta^{-1}(B) = \xi^{-1}(f^{-1}(B)) \in \mathcal{F}$, а это в точности означает, что $\eta$ является $(\mathcal{F}, \mathcal{B}(\mathbb{R}))$-измеримой функцией, то есть случайной величиной.

---

<h3 id="p2p2p2"><center>Понятие случайного вектора</center></h3>

==Опр.==**Случайный вектор** - это упорядоченный набор случайных величин $\overrightarrow{\xi}=(\xi_1, \dots, \xi_n)$, заданных на одном и том же вероятностном пространстве

> [!NOTE] Совместное распределение и векторы
> Для случайных векторов вводится **совместная функция распределения**: $$F_{\overrightarrow{\xi}}\ (x_1, x_2, \dots, x_n) = P(\xi_1 \le x_1, \xi_2 \le x_2, \dots, \xi_n \le x_n)$$Она полностью описывает статистическую связь между компонентами вектора.

---

<h3 id="p2p2p3"><center>Независимость случайных величин</center></h3>

==Опр.== СВ $\xi$ и $\eta$ - **независимые** $\Leftrightarrow$ $\forall A, B \in \mathcal{B}(\mathbb{R})$ события $\{\xi \in A\}$ и $\{\eta \in B\}$ 

==Опр.== СВ $\{\xi_i\}_{i=1}^n$ - **независимые попарно** $\Leftrightarrow$ $\forall i, j \in \overline{1,n}\ :\ \xi_i$ и $\xi_j$ - независимые 

==Опр.== СВ $\{\xi_i\}_{i=1}^n$ - **независимые в совокупности** $\Leftrightarrow$ $\forall \{A_i\}_{i=1}^n \subset \mathcal{B}(\mathbb{R})\ :\ P(\bigcap\limits_{i=1}^n \{\xi_i \in A_i\}) = \prod\limits_{i=1}^n P(\xi_i \in A_i)$

### Инвариантность независимости измеримого отображения

- Пусть $\{\xi_i\}_{i=1}^n$ - независимые в совокупности СВ, а $\{f_i\}_{i=1}^n \subset \mathcal{M}_1$, тогда $\{f_i(\xi_i)\}_{i=1}^n$ - независимые в совокупности СВ
#### Доказательство

Рассмотрим преобразованные СВ $\eta_i = f_i \circ \xi_i$.

1. Возьмём произвольные борелевские множества $\{B_i\}_{i=1}^n \subset \mathcal{B}(\mathbb{R})$. Нам нужно доказать, что$$
    \mathsf{P}(\eta_1 \in B_1, \eta_2 \in B_2, \dots, \eta_n \in B_n) = \prod_{i=1}^n \mathsf{P}(\eta_i \in B_i)
    $$
2. Переходим к прообразам:$$
    \mathsf{P}(\eta_1 \in B_1, \dots, \eta_n \in B_n) = P\left( \bigcap\limits_{i=1}^n\{\omega | f_i(\xi_i(\omega)) \in B_i\}\right)$$
3. Условие $f_i(\xi_i(\omega)) \in B_i$ эквивалентно условию $\xi_i(\omega) \in f_i^{-1}(B_i)$. Так как $f_i$ - борелевская функция, для $B_i \in \mathcal{B}(\mathbb{R})$ прообраз $f_i^{-1}(B_i)$ также является борелевским множеством: $f_i^{-1}(B_i) \in \mathcal{B}(\mathbb{R})$. Следовательно, мы можем записать:$$\{\omega: f_i(\xi_i(\omega)) \in B_i\} = \{\omega: \xi_i(\omega) \in f_i^{-1}(B_i)\}
    = \xi_i^{-1}(f_i^{-1}(B_i))$$

4. Подставляем в вероятность:$$\mathsf{P}(\eta_1 \in B_1, \dots, \eta_n \in B_n) = P\left( \bigcap\limits_{i=1}^n\{\omega | \xi_i(\omega) \in f_i^{-1}(B_i)\}\right)$$

5. Поскольку $\{\xi_i\}_{i=1}^n$ независимы в совокупности, а множества $f_i^{-1}(B_i)$ - борелевские:$$
    \mathsf{P}\left( \xi_1 \in f_1^{-1}(B_1), \dots, \xi_n \in f_n^{-1}(B_n) \right) = \prod_{i=1}^n \mathsf{P}\left( \xi_i \in f_i^{-1}(B_i) \right)$$
6. Возвращаемся к $\eta_i$: Заметим, что $\mathsf{P}(\xi_i \in f_i^{-1}(B_i)) =$ $\mathsf{P}(f_i(\xi_i) \in B_i) =$ $\mathsf{P}(\eta_i \in B_i)$. Подставляя это в произведение, получаем:$$\prod_{i=1}^n \mathsf{P}\left( \xi_i \in f_i^{-1}(B_i) \right) = \prod_{i=1}^n \mathsf{P}(\eta_i \in B_i)$$

7. Таким образом, для $\forall \{B_i\}_{i=1}^n \subset \mathcal{B}(\mathbb{R})$ выполняется:$$
    \mathsf{P}(\eta_1 \in B_1, \dots, \eta_n \in B_n) = \prod_{i=1}^n \mathsf{P}(\eta_i \in B_i)$$это по определению означает, что СВ $\{\eta_i\}_{i=1}^n$ независимы в совокупности.

---
<div style="page-break-after: always;"></div>


## <h2 id="p2p3"><center>Математическое ожидание</center></h2>

==Опр.== **Математическое ожидание (матожидание) СВ $\xi$** - это числовой функционал, определяемый как взвешенное среднее значений случайной величины:$$\mathbb{E}\xi = \int\limits_{\mathbb{R}}\xi dP = \int\limits_{-\infty}^{+\infty}\xi(\omega) \cdot P(d\omega)$$
> [!warning] Важно
> <p align="justify">Матожидание существует только в том случае, если данный интеграл <strong>сходится абсолютно</strong>. Если интеграл сходится условно, то матожидания не существует. Если интеграл расходится, то говорят, что матожидание бесконечно или что его не существует.</p>

==Опр.== **$m$-й (абсолютный) момент** СВ $\xi$ - $\mathbb{E}\xi^m$

==Опр.== **$m$-й центральный момент** СВ $\xi$ - $\mathbb{E}(\xi^c)^m$, где $\xi^c$ - центровка $\xi$

### Свойства математического ожидания

1. Матожидание - первый абсолютный момент.
2. $E(\alpha\xi + \beta\eta) = \alpha E\xi + \beta E\eta$ - *линейность*
3) $\forall c \in \mathbb{R}\ :\ \mathbb{E}c = c$
4) $\forall A \in \mathcal{F}\ :\ \mathbb{E1}_A = P(A)$
5) $\forall \xi \geq 0\ :\ E\xi \geq 0$
6) $\xi \geq \eta\ \Longrightarrow\ \mathbb{E}\xi \geq \mathbb{E}\eta$ - *монотонность*
7) $\mathbb{E}(\xi\eta) \leq \sqrt{\mathbb{E}\xi^2 \cdot \mathbb{E}\eta^2}$ - неравенство КБШ. (Причём $\mathbb{E}(\xi\eta) = \sqrt{\mathbb{E}\xi^2 \cdot \mathbb{E}\eta^2}$ $\Leftrightarrow$ $\exists c = const,\ \eta = c \cdot \xi$)

- Доказательства аналогичны [[#Свойства матожидания|дискретному случаю]]

### Матожидание независимых СВ

- Если $\xi$ и $\eta$ - независимые СВ, то $\mathbb{E}(\xi \eta) = (\mathbb{E}\xi)(\mathbb{E} \eta)$

#### Доказательство

1. Для ДСВ данная теорема уже была доказана ранее.

2. Рассмотрим случай стохастических неотрицательных СВ. Пусть $\xi, \eta \geq 0$. Рассмотрим монотонные последовательности простых функций: $$\begin{align}
    \{\xi_n\}_{n=1}^{\infty} - \text{последовательность неотрицательных ДСВ т.ч.}\ \\ \forall \omega \in \Omega\ :\  \lim\xi_n(\omega) \to \xi(\omega), \forall n \in \mathbb{N}\ :\ \xi_n \leq \xi \\ \{\eta_n\}_{n=1}^{\infty} - \text{последовательность неотрицательных ДСВ т.ч.}\ \\ \forall \omega \in \Omega\ :\  \lim\eta_n(\omega) \to \eta(\omega), \forall n \in \mathbb{N}\ :\ \eta_n \leq \eta 
    \end{align}$$При этом можно выбрать $\xi_n$ и $\eta_n$ так, что они будут независимыми (поскольку $\xi$ и $\eta$ независимы, их аппроксимации можно сразу строить на независимых разбиениях). Для них, как доказано, выполняется $\mathbb{E}(\xi_n \eta_n) = \mathbb{E}\xi_n \cdot \mathbb{E}\eta_n$.
    Переходя к пределу при $n \to \infty$ и применяя теорему Лебега о монотонной сходимости трижды к последовательностям $\xi_n$, $\eta_n$ и $\xi_n \eta_n$, получаем:$$ \mathbb{E}(\xi \eta) = \lim_{n \to \infty} \mathbb{E}(\xi_n \eta_n) = \lim_{n \to \infty} (\mathbb{E}\xi_n \cdot \mathbb{E}\eta_n) = (\lim_{n \to \infty} \mathbb{E}\xi_n) \cdot (\lim_{n \to \infty} \mathbb{E}\eta_n) = (\mathbb{E}\xi)(\mathbb{E}\eta)$$
3. Общий случай. Для произвольных $\xi$ и $\eta$ используем разложение на положительную и отрицательную части:$\xi = \xi^+ - \xi^-$, $\eta = \eta^+ - \eta^-$. Величины $\xi^+, \xi^-, \eta^+, \eta^-$ неотрицательны и попарно независимы (как борелевские функции от независимых СВ), Тогда  $\xi \eta = \xi^+ \eta^+ - \xi^+ \eta^- - \xi^- \eta^+ + \xi^- \eta^-$ и применяя результат для неотрицательных СВ и линейность матожидания, получаем требуемое равенство: $\mathbb{E}(\xi \eta) = (\mathbb{E}\xi)(\mathbb{E} \eta)$.

### Матожидание ограниченной СВ

- Если $\exists C > 0$ т.ч. $\forall \omega\ :\ |\xi(\omega)| \leq C$, то $\exists \mathbb{E} \xi \in \mathbb{R}$

#### Доказательство
$$\mathbb{E}\xi = \int_\Omega |\xi(\omega)| dP(\omega) \leq \int_\Omega C \, dP(\omega) = C \cdot P(\Omega) = C < \infty$$

---

## <h2 id="p2p4"><center>Дисперсия</center></h2>

==Опр.== **Дисперсия** СВ $\xi$ - это функционал, характеризующий разброс значений СВ относительно её ожидания:
$$\mathbb{D}\xi = \mathbb{E}(\xi - \mathbb{E}\xi)^2 = \mathbb{E}\xi^2 - (\mathbb{E}\xi)^2$$

==Опр.== **Среднее квадратичное отклонение** $\sigma(\xi) = \sqrt{\mathbb{D}\xi}$

### Свойства дисперсии
1. Дисперсия - второй центральный момент.
2. $\mathbb{D}\xi \ge 0$ - *неотрицательность*
3. =$\mathbb{D}\xi = 0 \iff \xi = const$ (почти наверное)
4. =$\forall c \in \mathbb{R}\ :\ \mathbb{D}(c\xi) = c^2 \mathbb{D}\xi$
5. Дисперсия НЕ линейна. (Контрпример: $\eta = 2\xi$)

> [!info] Инфо
> Центровка и нормировка СВ определяются так же, как в [[#<h2 id="p1p6"><center>Дискретные случайные величины</center></h2>|дискретном случае]]

---

## <h2 id="p2p5"><center>Ковариация</center></h2>

==Опр.== **Ковариация** - это мера линейной зависимости двух случайных величин:$$cov(\xi, \eta) = E(\xi^c \cdot \eta^c) = E(\xi\eta) - E\xi E\eta$$
### Дискретный случай

Пусть $\{x_i\}_{i=1}^n$ и $\{y_j\}_{j=1}^m$ - коэффициенты $\xi$ и $\eta$ соотв. из теоремы о простоте ДСВ, тогда $$cov(\xi,\ \eta) = \sum\limits_{i=1}^n \sum\limits_{j=1}^m x_i y_j\ P(\xi = x_i,\ \eta = y_j)$$
### Свойства ковариации

1. $cov(\xi, \eta) = cov(\eta, \xi)$ - *симметричность*
2. $cov(c_1\xi_1 + c_2\xi_2, \eta) = c_1 cov(\xi_1, \eta) + c_2 cov(\xi_2, \eta)$ - *билинейность*
3. $cov(\xi, \xi) = \mathbb{D}\xi$

#### Доказательство

1. $cov(\xi, \eta) =$ $\mathbb{E}(\xi\eta) - \mathbb{E}\xi\mathbb{E}\eta =$ $\mathbb{E}(\eta\xi) - \mathbb{E}\eta\mathbb{E}\xi =$ $cov(\eta, \xi)$
2. $cov(c_1\xi_1 + c_2\xi_2, \eta) =$ $\mathbb{E}((c_1\xi_1 + c_2\xi_2)\eta) - \mathbb{E}(c_1\xi_1 + c_2\xi_2)\mathbb{E}\eta =$ $\mathbb{E}(c_1\xi_1\eta + c_2\xi_2\eta) - (c_1\mathbb{E}\xi_1 + c_2\mathbb{E}\xi_2)\mathbb{E}\eta =$ $c_1\mathbb{E}(\xi_1\eta) + c_2\mathbb{E}(\xi_2\eta) - c_1\mathbb{E}\xi_1\mathbb{E}\eta - c_2\mathbb{E}\xi_2\mathbb{E}\eta =$ $c_1(\mathbb{E}(\xi_1\eta) - \mathbb{E}\xi_1\mathbb{E}\eta) + c_2(\mathbb{E}(\xi_2\eta) - \mathbb{E}\xi_2\mathbb{E}\eta)$ $= c_1 cov(\xi_1, \eta) + c_2 cov(\xi_2, \eta)$
3. $cov(\xi, \xi) =$ $\mathbb{E}(\xi^2) - (\mathbb{E}\xi)^2 =$ $\mathbb{D}\xi$

### Достаточное условие нулевой ковариации
$$\xi\ \text{и}\ \eta\ -\ \text{независимые случайные величины}\ \Longrightarrow cov(\xi,\ \eta) = 0$$

> [!IMPORTANT] Замечание
> Если $cov(\xi, \eta) = 0$, то говорят, что $\xi$ и $\eta$ некоррелированные. Из того, что СВ некоррелированы не следует их независимость. Контрпример: $\xi$ принимает значения $-1, 0, 1$ с вероятностями $\frac{1}{4}, \frac{1}{2}, \frac{1}{4}$ соотв., а $\eta = \xi^2$.

#### Доказательство

Из условия независимости: $\mathbb{E}(\xi\eta) = \mathbb{E}\xi \cdot \mathbb{E}\eta$, тогда по определению ковариации: $cov(\xi, \eta) =$ $\mathbb{E}(\xi\eta) - \mathbb{E}\xi\mathbb{E}\eta =$ $\mathbb{E}\xi\mathbb{E}\eta - \mathbb{E}\xi\mathbb{E}\eta$ $= 0$

### Дисперсия суммы СВ

Пусть $\{\xi_i\}_{i=1}^n$ - СВ т.ч. $\forall i \in \overline{1, n}\ :\ \exists\ \mathbb{E}\xi_i$ и $\exists\ \mathbb{D}\xi_i$, тогда $$\mathbb{D}(\sum\limits_{i=1}^n \xi_i) = \sum\limits_{i=1}^n \mathbb{D}\xi_i + \sum\limits_{i=1}^n \sum\limits_{j=1,\ i \neq j}^n cov(\xi_i,\ \xi_j)$$
#### Доказательство

Обозначим $S = \sum\limits_{i=1}^n \xi_i$. Тогда по определению дисперсии: $\mathbb{D}S =$ $\mathbb{E}(S - \mathbb{E}S)^2 =$ $\mathbb{E}\left(\left(\sum\limits_{i=1}^n (\xi_i - \mathbb{E}\xi_i)\right)^2\right) =$ $\mathbb{E}\left(\sum\limits_{i=1}^n \sum\limits_{j=1}^n (\xi_i - \mathbb{E}\xi_i)(\xi_j - \mathbb{E}\xi_j)\right) =$ $\sum\limits_{i=1}^n \sum\limits_{j=1}^n \mathbb{E}((\xi_i - \mathbb{E}\xi_i)(\xi_j - \mathbb{E}\xi_j)) =$ $\sum\limits_{i=1}^n \mathbb{E}((\xi_i - \mathbb{E}\xi_i)^2) + \sum\limits_{i=1}^n \sum\limits_{j=1,\ j\neq i}^n \mathbb{E}((\xi_i - \mathbb{E}\xi_i)(\xi_j - \mathbb{E}\xi_j)) =$ $\sum\limits_{i=1}^n \mathbb{D}\xi_i + \sum\limits_{i=1}^n \sum\limits_{j=1,\ j\neq i}^n cov(\xi_i, \xi_j)$

#### Следствия

1) $\mathbb{D}(\xi + \eta) = \mathbb{D}\xi + 2cov(\xi,\ \eta) + \mathbb{D}\eta$
2) Если $\xi$ и $\eta$ - независимые, то $\mathbb{D}(\xi + \eta) = \mathbb{D}\xi + \mathbb{D}\eta$

---

## <h2 id="p2p6"><center>Корреляция</center></h2>

==Опр.==**Коэффициент корреляции (корреляция)** - это безразмерная характеристика силы линейной связи:$$\rho(\xi, \eta) = \frac{cov(\xi, \eta)}{\sqrt{\mathbb{D}\xi} \sqrt{\mathbb{D}\eta}}$$
==Опр.== $\xi$ и $\eta$ - **некоррелированные** СВ $\Leftrightarrow$ $\rho(\xi,\ \eta) = 0$ ($\Longleftrightarrow$ $cov(\xi, \eta) = 0$, то есть некоррелированность в замечании выше и здесь - одно и то же понятие)

### Свойства коэффициента корреляции

1) $\rho(\xi, \eta) \in [-1; 1]$ - *ограниченность*

#### Доказательство

Применим неравенство КБШ к центрированным величинам: $|\mathbb{E}(\xi^c\eta^c)| \leq \sqrt{\mathbb{E}[(\xi^c)^2]\mathbb{E}[(\eta^c)^2]}$, но $\mathbb{E}(\xi^c\eta^c) = cov(\xi, \eta)$, а $\mathbb{E}[(\xi^c)^2] = \mathbb{D}\xi$ и $\mathbb{E}[(\eta^c)^2] = \mathbb{D}\eta$. Тогда: $|cov(\xi, \eta)| \leq \sqrt{\mathbb{D}\xi \cdot \mathbb{D}\eta}$. Разделим обе части на $\sqrt{\mathbb{D}\xi \cdot \mathbb{D}\eta} > 0$:$$\left|\frac{cov(\xi, \eta)}{\sqrt{\mathbb{D}\xi \cdot \mathbb{D}\eta}}\right| \leq 1 \quad \Rightarrow \quad |\rho(\xi, \eta)| \leq 1$$Таким образом, $\rho(\xi, \eta) \in [-1, 1]$

Мы до этого смело делили $\sqrt{\mathbb{D}\xi \cdot \mathbb{D}\eta}$, но оно могло быть $=0$. Рассмотрим этот случай отдельно. Если $\mathbb{D}\xi = 0$ или $\mathbb{D}\eta = 0$, то коэффициент корреляции не определён, но в этом случае одна из величин *(почти наверное)* постоянна, и связь с ней тривиальна.

### Теорема о линейной зависимости случайных величин
$$\rho(\xi,\ \eta) = \pm1 \Longrightarrow\ \exists a > 0\ \exists b \in \mathbb{R}\ :\ \eta = \pm a\xi + b\ \text{(почти наверное)}$$
#### Доказательство

Рассмотрим случай $\rho(\xi, \eta) = 1$ (случай $\rho = -1$ доказывается аналогично).

Применим неравенство КБШ к центрированным СВ. Оно обращается в равенство $\Longleftrightarrow$ СВ линейно зависимы. В нашем случае: $|\mathbb{E}(\xi^c\eta^c)| = \sqrt{\mathbb{D}\xi \cdot \mathbb{D}\eta}$ $\Longleftrightarrow$ $\exists \lambda \in \mathbb{R}$ т.ч. $\eta^c = \lambda \xi^c$ *(почти наверное)*

Из условия $\rho = 1$ следует равенство в неравенстве:$$\rho(\xi, \eta) = \frac{cov(\xi, \eta)}{\sqrt{\mathbb{D}\xi \cdot \mathbb{D}\eta}} = 1 \quad \Longrightarrow \quad cov(\xi, \eta) = \sqrt{\mathbb{D}\xi \cdot \mathbb{D}\eta}$$Но $cov(\xi, \eta) = \mathbb{E}(\xi^c\eta^c)$, поэтому: $\mathbb{E}(\xi^c\eta^c) = \sqrt{\mathbb{E}(\xi^c)^2\mathbb{E}(\eta^c)^2}$
Применяем критерий равенства: $\exists \lambda \in \mathbb{R}$ т.ч. $\eta^c = \lambda \xi^c$ *(почти наверное)*. Найдём $\lambda$:$$\lambda = \frac{cov(\xi, \eta)}{\mathbb{D}\xi} = \frac{\sqrt{\mathbb{D}\xi \cdot \mathbb{D}\eta}}{\mathbb{D}\xi} = \sqrt{\frac{\mathbb{D}\eta}{\mathbb{D}\xi}} > 0$$
Переходим к исходным величинам: $\eta - \mathbb{E}\eta = \lambda(\xi - \mathbb{E}\xi)$ (почти наверное) Обозначим $a = \lambda > 0$ и $b = \mathbb{E}\eta - \lambda\mathbb{E}\xi$, тогда: $\eta = a\xi + b$ (почти наверное)

---

## <h3 id="p2p6p2"><center>Задача о линейном прогнозе</center></h3>

## Формулировка задачи

Пусть $Y$ и $Z$ - СВ. Найти **оптимальный линейный прогноз** $Y$ по $Z$ означает найти такую СВ $Y^* = aZ + b$, что $\mathbb{E}(Y^* - Y)^2$ минимально возможно.

## Аналитическое решение

Подставим $Y^*$ во второй абсолютный момент: $Q(a,\ b)=$ $\mathbb{E}(Y^* - Y)^2 =$ $\mathbb{E}(Y^* - aZ - b)^2 =$ $\mathbb{E}Y^2 + a^2\mathbb{E}Z^2 + b^2 - 2a\mathbb{E}(YZ) - 2b\mathbb{E}Y + 2ab\mathbb{E}Z$

Найдём экстремумы ФМП $Q$:$$\begin{cases} \frac{\partial Q}{\partial a}(a, b) = 2a\mathbb{E}Z^2 - 2\mathbb{E}(YZ) + 2b\mathbb{E}(Z) = 0 \\ \frac{\partial Q}{\partial b}(a, b) = 2b - 2\mathbb{E}Y + 2a\mathbb{E}Z = 0 \end{cases}$$Решая систему относительно $a$ и $b$, получаем единственную стационарную точку, которая и будет локальным минимумом:$$\begin{cases} a = \frac{\mathbb{E}(YZ)}{\mathbb{D}Z} = \frac{cov(Y, Z)}{\mathbb{D}Z} \\ b = \mathbb{E}Y - \frac{cov(Y, Z)}{\mathbb{D}Z} \mathbb{E}Z \end{cases}$$
## Геометрическое решение

Пусть $L$ - множество случайных величин в одном и том ВП с конечными матожиданиями. 
1) $\forall \xi, \eta \in L\ :\ \xi + \eta = \eta + \xi$ - тоже СВ, причём $\mathbb{E}(\xi + \eta) = \mathbb{E}\xi + \mathbb{E}\eta \in \mathbb{R}$
2) $\forall c \in \mathbb{R}\ \forall \xi \in L\ :\ c \cdot \xi$ - тоже СВ, причём $\mathbb{E}(c\xi) = c\mathbb{E}\xi \in \mathbb{R}$
3) $0$ - СВ, причём $\forall \xi \in L\ :\ \xi + 0 = 0 + \xi = \xi$
4) $(\xi + \eta) + \nu = \xi + (\eta + \nu)$
5) $c(\xi + \eta) = c\xi + c\eta$

Получается, что $L$ - ЛП. Пусть $(\xi,\ \eta) = cov(\xi,\ \eta)$. Из свойств [[#<h2 id="p2p5"><center>Ковариация</center></h2>|ковариации]], она:
1) билинейна
2) симметрична
3) положительно определена

Тогда $L$ с определённой ковариацией на ней является **евклидовым** пространством. Заметим, что $\mathbb{E}(Y^* - Y)^2 \to min$ $\Leftrightarrow$ $cov(Y^* - Y,\ Y^* - Y) \to min$ $\Leftrightarrow$ $|| Y^* - Y || \to min$

$Y^*$ - ЛК СВ $1$ и $Z$ $\Rightarrow$ $Y^*$ лежит в подпространстве  $L' =\ <1,\ Z>$, а $|| Y^* - Y || \to min$ достигается, когда $Y^* = Пр_{\perp\ L'}(Y)$

Если $Z = const$, то $\dim L' = 1$ $\Rightarrow$ $Y^* = \mathbb{E}Y$. Пусть $Z \neq const$.

Выберем ОНБ в $L'$:
1) $e_1 = 1$ - уже нормированный базисный вектор
2) $e_2 = \frac{Z - (Z,\ 1)}{||Z - (Z,\ 1)||}$ $= \frac{Z - \mathbb{E}Z}{\sqrt{\mathbb{D}Z}}$ $= Z^n$

тогда $Y^* = (Y, e_1)e_1 + (Y, e_2)e_2$ $= \mathbb{E}Y + \mathbb{E}(YZ^n)Z^n$ $= \mathbb{E}Y + Z^c \cdot \frac{cov(Y, Z)}{\mathbb{D}Z}$

Итог:$$\begin{cases} a = \frac{cov(Y, Z)}{\mathbb{D}Z} \\ b = \mathbb{E}Y - a \mathbb{E}Z \end{cases}$$

---
<div style="page-break-after: always;"></div>


## <h2 id="p2p7"><center>Неравенства Чебышёва-Маркова</center></h2>

### Неравенство Маркова (I-е неравенство Чебышёва)
$$\forall\ \text{СВ}\ \xi \geq 0\ \forall \varepsilon >0\ :\ P(\xi \geq \varepsilon) \leq \frac{\mathbb{E}\xi}{\varepsilon}$$
#### Доказательство

Так как $\xi \geq 0$ $\Rightarrow$ $\exists \mathbb{E}\xi \in [0; +\infty]$. Если $\mathbb{E}\xi = +\infty$, то неравенство очевидно выполняется в силу ограниченности вероятности. Пусть $\mathbb{E}\xi < +\infty$, тогда $\Omega = \{\xi < \varepsilon\} + \{\xi \geq \varepsilon\}$ $\Rightarrow$ $1 \equiv \mathbb{1}_{\Omega} =$ $\mathbb{1}_{\{\xi < \varepsilon\}} + \mathbb{1}_{\{\xi \geq \varepsilon\}}$ $\Rightarrow$ $\xi = \xi\mathbb{1}_{\{\xi < \varepsilon\}} + \xi\mathbb{1}_{\{\xi \geq \varepsilon\}}$ $\geq \xi\mathbb{1}_{\{\xi \geq \varepsilon\}} \geq$ \[т.к. на этом множестве $\xi \geq \varepsilon$\] $\geq \varepsilon\mathbb{1}_{\{\xi \geq \varepsilon\}}$ $\Rightarrow$ в силу монотонности матожидания: $\mathbb{E}\xi \geq$ $\mathbb{E}(\varepsilon\mathbb{1}_{\{\xi \geq \varepsilon\}}) =$ $\varepsilon P(\xi \geq \varepsilon)$ - доказано.

#### Следствие
$$\forall\ \text{СВ}\ \xi \geq 0\ \forall f\uparrow\ \forall c \in \mathbb{R}\ :\ P(\xi \geq c) \leq \frac{\mathbb{E}f(\xi)}{f(c)}$$
### Неравенство Чебышёва (II-е неравенство Чебышёва)
$$\forall\ \text{СВ}\ \xi\ \text{т.ч.}\ \mathbb{D}\xi \in \mathbb{R} \ \forall \varepsilon >0\ :\ P(|\xi - \mathbb{E}\xi| \geq \varepsilon) \leq \frac{\mathbb{D}\xi}{\varepsilon^2}$$
#### Доказательство

$\mathbb{D}\xi \in \mathbb{R}$ $\Rightarrow$ $\exists\mathbb{E}\xi \in \mathbb{R}$, пусть $\eta = (\xi^c)^2$ $\Rightarrow$ По неравенству Маркова $P(\eta \geq \varepsilon^2) =$ $P((\xi - \mathbb{E}\xi)^2 \geq \varepsilon^2) =$ $P(|\xi - \mathbb{E}\xi| \geq \varepsilon) \leq$ $\frac{\mathbb{E}\eta}{\varepsilon^2} =$ $\frac{\mathbb{D}\xi}{\varepsilon^2}$

> [!important] Правило трёх сигм
> Пусть $\xi$ - СВ, для которой $\exists$ [[#<h2 id="p2p4"><center>Дисперсия</center></h2>|стандартное отклонение]] $\sigma(\xi)$, тогда$$P(|\xi - \mathbb{E}\xi| < 3\sigma(\xi)) \geq \frac{8}{9}$$
> **Доказательство:** Если $\sigma(\xi) = +\infty$, то $P(|\xi - \mathbb{E}\xi| < 3\sigma(\xi)) = 1 \geq \frac{8}{9}$ - тривиально. Рассмотрим случай $\sigma(\xi) \in \mathbb{R}$, тогда по II-му неравенству Чебышёва для $\varepsilon = 3\sigma(\xi)$ выполняется: $P(|\xi - \mathbb{E}\xi| < 3\sigma(\xi)) =$ $1 - P(|\xi - \mathbb{E}\xi| \geq$ $3\sigma(\xi)) \geq$ $1 - \frac{\mathbb{D}\xi}{(3\sigma(\xi))^2}$ $= 1 - \frac{\sigma(\xi)^2}{(3\sigma(\xi))^2} =$ $\frac{8}{9}$

---
<div style="page-break-after: always;"></div>


# <h1 id="p3"><center>Распределение случайных величин</center></h1>
## <h2 id="p3p1"><center>Функция распределения</center></h2>

==Опр.== **Функция распределения** *(распределение СВ $\xi$)* - $F_{\xi}(x) = P(\xi \le x)$

> [!success] Всюдуопределённость
> Данная функция $\exists$ и определена всюду для $\forall$ СВ, т.к. прообраз $\xi^{-1}((-\infty; x])$ является событием по определению СВ

==Опр.== **Стохастическая эквивалентность СВ** *(эквивалентность по распределению)* - $\xi$ $\sim_{F}$ $\eta$ $\Leftrightarrow$ $\forall x\ :\ F_{\xi}(x) = F_{\eta}(x)$

==Опр.== **СВ ($\xi$) с симметричным распределением** $\Leftrightarrow$ $\xi$ $\sim_{F}$ $(-\xi)$ 

==Опр.== СВ $\{\xi_i\}$ - **одинаково распределены**, если они попарно стохастически эквивалентны.

### Свойства функции распределения

1) $\forall x\ :\ F(x) \in [0;\ 1]$ - *ограниченность*
2) $\forall a, b \in \mathbb{R}\ :\ a \le b \Leftrightarrow F(a) \le F(b)$ - *монотонность*
3) $\forall x \in \mathbb{R}\ :\ F(x+0) = F(x)$ - *непрерывность справа*
4) $\forall a \in \mathbb{R}\ :\ P(\xi = a) = F_{\xi}(a + 0) - F_{\xi}(a-0)$
5) $F(-\infty) = 0$, $F(+\infty) = 1$

#### Доказательство

1) Вероятность любого события (в том числе $\{\xi \le x\}$) принадлежит отрезку $[0; 1]$, так как это мера, удовлетворяющая аксиомам Колмогорова
2) Пусть $a \le b$ тогда $\{\xi \le a\} \subseteq \{\xi \le b\}$ и в силу монотонности вероятности $P(\xi \le a) \le P(\xi \le b)$ $\Leftrightarrow$ $F(a) \le F(b)$
3) Рассмотрим произвольную убывающую последовательность $\{x_n\}_{n=1}^\infty$ т.ч. $x_n \downarrow x$ (т.е. $x_n \ge x$ и $x_n \to x$), тогда события $A_n = \{\xi \le x_n\}$ образуют убывающую последовательность ($\forall n \in \mathbb{N}\ :\ A_{n+1} \subseteq A_n$). Предел этой последовательности: $\bigcap\limits_{n=1}^\infty A_n = \{\xi \le x\}$. По свойству непрерывности вероятностной меры: $\lim\limits_{n \to \infty} P(A_n) =$ $P\left(\bigcap\limits_{n=1}^\infty A_n\right) =$ $P(\xi \le x)$. Но $\lim\limits_{n \to \infty} P(A_n) =$ $\lim\limits_{n \to \infty} F(x_n) =$ $F(x+0)$, следовательно, $F(x+0) = F(x)$
4) Рассмотрим событие $\{\xi = a\}$. Его можно представить как разность $\{\xi = a\} = \{\xi \le a\} / \{\xi < a\}$, при этом $\{\xi < a\} = \bigcup\limits_{n=1}^\infty \{\xi \le a - \frac{1}{n}\}$, тогда $P(\xi = a) =$ $P(\xi \le a) - P(\xi < a) =$ $F(a) - \lim\limits_{n \to \infty} P\left(\xi \le a - \frac{1}{n}\right) =$ $F(a) - \lim\limits_{x \to a - 0} F(x) =$ $F(a+0) - F(a-0)$
5) Предельные значения:
	1) При $x \to -\infty$: рассмотрим убывающую последовательность $x_n \to -\infty$, тогда события $A_n = \{\xi \le x_n\}$ убывают к пустому множеству: $\bigcap\limits_{n=1}^\infty \{\xi \le x_n\} = \varnothing$. По непрерывности меры: $\lim\limits_{n \to \infty} F(x_n) =$ $\lim\limits_{n \to \infty} P(\xi \le x_n) =$ $P(\varnothing) = 0$, следовательно, $F(-\infty) =$ $\lim\limits_{x \to -\infty} F(x) = 0$.
	2. При $x \to +\infty$: рассмотрим возрастающую последовательность $x_n \to +\infty$. Тогда события $A_n = \{\xi \le x_n\}$ возрастают ко всему пространству элементарных исходов: $\bigcup\limits_{n=1}^\infty \{\xi \le x_n\} = \Omega$. По непрерывности меры: $\lim\limits_{n \to \infty} F(x_n) =$ $\lim\limits_{n \to \infty} P(\xi \le x_n) =$ $P(\Omega) = 1$, следовательно, $F(+\infty) =$ $\lim\limits_{x \to +\infty} F(x) = 1$.

### Инвариантность одинакового распределения измеримого отображения

- Пусть $\{\xi_i\}_{i=1}^n$ - попарно стохастически эквивалентные СВ, а $f \in \mathcal{M}_1$, тогда $\{f(\xi_i)\}_{i=1}^n$ - попарно стохастически эквивалентные СВ

#### Доказательство

Заметим, что: $\forall y \in \mathbb{R}\ :\ \{f(\xi) \le y\} =$ $\{\omega \in \Omega \mid f(\xi(\omega)) \le y\} =$ $\{\omega \in \Omega \mid \xi(\omega) \in f^{-1}((-\infty, y])\}$, при этом множество $B_y = f^{-1}((-\infty, y])$ является борелевским, так как $f$ измерима, а $(-\infty, y] \in \mathcal{B}(\mathbb{R})$.

По определению стохастической эквивалентности и эквивалентным определениям СВ: $\forall i, j \in \overline{1,n}\ \forall y \in \mathbb{R} :$ $P(\xi_i \le y) =$ $P(\xi_j \le y)$ $\Longleftrightarrow$  $\forall i, j \in \overline{1,n}\ :$ $P(\xi_i \in B_y) =$ $P(\xi_j \in B_y)$, а это значит $F_{f(\xi_i)}(y) =$ $P(f(\xi_i) \le y) =$ $P(\xi_i \in f^{-1}((-\infty, y])) =$ $P(\xi_j \in f^{-1}((-\infty, y])) =$ $P(f(\xi_j) \le y) =$ $F_{f(\xi_j)}(y)$

#### Следствие

- Если $\xi$ имеет симметричное распределение, а $f \in \mathcal{M}_1$ - нечётная функция, то $f(\xi) \sim_F f(-\xi) \sim_F -f(\xi)$

## НОРСВ

==Опр.== $\{\xi_i\}$ - **Независимые одинаково распределённые случайные величины** *(НОРСВ)* $\Leftrightarrow$ они [[#<h2 id="p2p2"><center>Стохастические случайные величины</center></h2>|независимы в совокупности]] и попарно стохастически эквивалентны

### Теорема об инвариантности НОРСВ под измеримым отображением

- Пусть $\{\xi_i\}_{i=1}^n$ - НОРСВ, а $f \in \mathcal{M}_1$, тогда $\{f(\xi_i)\}_{i=1}^n$ - НОРСВ

#### Доказательство.

Применяем последовательно теорему об [[#Инвариантность независимости измеримого отображения|инвариантности независимости]] и [[#Инвариантность одинакового распределения измеримого отображения|инвариантности одинаковораспределённости]].

---

## <h2 id="p3p1"><center>Плотность распределения</center></h2>

==Опр.== **Абсолютно непрерывная СВ** - СВ $\xi$, у которой функция распределения может быть представлена в виде:$$F_{\xi}(x) = \int\limits_{-\infty}^xp_{\xi}(t)dt$$
==Опр.== **Плотность распределения** - это функция $p_{\xi}(t)$, стоящая под знаком интеграла в определении абсолютно непрерывной СВ.


> [!warning] Важно
> <p align="justify">Заметим, что для одной и той же функции распределения может существовать несколько различных плотностей распределения, но они будут попарно отличаться только на множестве точек меры нуль. Если есть возможность взять непрерывную плотность распределения, то мы будем ставить именно её в соответствие функции распределения.</p>

### Свойства плотности распределения

1) $\forall \xi\ :\ p_{\xi} \in L_1(\mathbb{R})$ - *интегрируемость по Лебегу*
2) $\forall t\ :\ p(t) \geq 0$ - *неотрицательность* (верно для всех точек непрерывности)
3) $\int\limits_{\mathbb{R}}p(t)dt = 1$ - *нормированность*

#### Доказательство.

1) Следует прямо из определения. Функция распределения определена всюду и ограничена, а плотность выходит интегрируема на любом борелевском множестве.
2) Пусть $x_1 < x_2$, тогда:$$F_\xi(x_2) - F_\xi(x_1) = \int\limits_{x_1}^{x_2} p_\xi(t) dt \geq 0$$так как $F_\xi$ не убывает, следовательно, для $\forall x_1 < x_2$:$$\int\limits_{x_1}^{x_2} p_\xi(t) dt \geq 0$$Если бы в некоторой точке $t_0$ плотность была отрицательна, то в силу измеримости нашёлся бы интервал $(x_1, x_2)$, содержащий $t_0$, на котором $p_\xi(t) < 0$ почти всюду, и тогда интеграл по этому интервалу был бы отрицательным, что противоречит неравенству выше. Следовательно, $p_\xi(t) \geq 0$ почти всюду (а в точках непрерывности - всюду).
3) Действительно: $$\int\limits_{\mathbb{R}} p_\xi(t) dt = \int\limits_{-\infty}^{+\infty} p_\xi(t) dt = \lim_{x \to +\infty} \int\limits_{-\infty}^x p_\xi(t) dt = \lim_{x \to +\infty} F_\xi(x) = 1$$

### Теорема о непрерывной плотности
$$\exists p_{\xi} \in \mathbb{C}({\mathbb{R}})\ \ \Longrightarrow\ \forall t \in \mathbb{R}\ :\ p_{\xi}(t) = F'_{\xi}(t)$$
#### Доказательство

Рассмотрим производную функции распределения в произвольной точке $t_0$:$$F'_\xi(t_0) = \lim_{h \to 0} \frac{F_\xi(t_0 + h) - F_\xi(t_0)}{h} = \lim_{h \to 0} \frac{1}{h} \int\limits_{t_0}^{t_0 + h} p_\xi(t) dt$$
В силу непрерывности $p_\xi$ в т. $t_0$, для $\forall \varepsilon > 0$ $\exists \delta > 0$ $\forall t \in U_{\delta}(t_0)$ верно $|p_\xi(t) - p_\xi(t_0)| < \varepsilon$. Представим $p_\xi(t)$ в виде $p_\xi(t) = p_\xi(t_0) + \eta(t)$, где $\eta(t) = p_\xi(t) - p_\xi(t_0)$. Тогда $|\eta(t)| < \varepsilon$ при $|t - t_0| < \delta$. Для $|h| < \delta$: $$\frac{1}{h} \int\limits_{t_0}^{t_0 + h} p_\xi(t) dt = \frac{1}{h} \int\limits_{t_0}^{t_0 + h} (p_\xi(t_0) + \eta(t)) dt$$
Оценим второе слагаемое:$$\left| \frac{1}{h} \int\limits_{t_0}^{t_0 + h} \eta(t) dt \right| \leq \frac{1}{|h|} \int\limits_{t_0}^{t_0 + h} |\eta(t)| dt \leq \frac{1}{|h|} \cdot \varepsilon \cdot |h| = \varepsilon$$
Так как $\varepsilon$ может быть выбрано сколь угодно малым, получаем:$$\lim_{h \to 0} \frac{1}{h} (\int\limits_{t_0}^{t_0 + h} p_\xi(t) dt + o(0)) = p_\xi(t_0)$$Следовательно, $F'_\xi(t_0) = p_\xi(t_0)$.

#### Замечание

- Если плотность не является непрерывной, то равенство $p_\xi(t) = F'_\xi(t)$ выполняется во всех точках, где $F_\xi$ дифференцируема.

### Теорема о сужении на событие
$$A \in \mathcal{B}(\mathbb{R})\ \ \Longrightarrow\ P(\xi \in A) = \int\limits_{A} p_{\xi} dP$$
#### Доказательство

1. Для полуинтервалов $A = (-\infty, x]$ утверждение верно по определению абсолютно непрерывной СВ:$$P(\xi \le x) = F_\xi(x) = \int\limits_{-\infty}^x p_\xi(t) dt = \int\limits_{(-\infty, x]} p_\xi(t) dt$$
2. Рассмотрим $A = (a; b]$, тогда:$$P(\xi \in (a, b]) = P(\xi \le b) - P(\xi \le a) = \int\limits_{-\infty}^b p_\xi(t) dt - \int\limits_{-\infty}^a p_\xi(t) dt = \int\limits_a^b p_\xi(t) dt = \int\limits_{(a, b]} p_\xi(t) dt$$То есть для интервалов тоже верно.

3. Докажем для конечных объединений непересекающихся полуинтервалов. Пусть $A = \bigcup\limits_{k=1}^n I_k$, где $I_k$ - непересекающиеся полуинтервалы вида $(a_k; b_k]$, тогда:$$P(\xi \in A) = \sum_{k=1}^n P(\xi \in I_k) = \sum_{k=1}^n \int\limits_{I_k} p_\xi(t) dt = \int\limits_A p_\xi(t) dt$$
4. Рассмотрим две меры на $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$:
	   - $\mu_1(A) = P(\xi \in A)$ - вероятностная мера, порождённая СВ $\xi$
	   - $\mu_2(A) = \int_A p_\xi(t) dt$ - мера с плотностью $p_\xi$
   Мы доказали, что $\mu_1$ и $\mu_2$ совпадают на классе полуинтервалов $(-\infty, x]$, и на всех полуинтервалах вида $(a, b]$, и на конечных объединениях таких полуинтервалов. Класс полуинтервалов $(a, b]$ является $\pi$-системой и порождает борелевскую $\sigma$-алгебру $\mathcal{B}(\mathbb{R})$.
5. По теореме о единственности меры, если две меры совпадают на $\pi$-системе, порождающей $\sigma$-алгебру, то они совпадают на всей $\sigma$-алгебре, следовательно, $\forall A \in \mathcal{B}(\mathbb{R})$:$$P(\xi \in A) = \mu_2(A) = \int\limits_A p_\xi(t) dt$$

---
<div style="page-break-after: always;"></div>


## <h2 id="p3p3"><center>Совместное распределение СВ</center></h2>

==Опр.== **Функция совместного распределения** *(СВ $\{\xi_i\}_{i=1}^n$)* - $F_{\{\xi_i\}_{i=1}^n}(x_1, x_2, \dots, x_n) = P(\bigcap\limits_{i=1}^n\{\xi_i = x_i\})$

## Свойства совместного распределения

1) $F_{\{\xi_i\}_{i=1}^n}$ - *неубывание по всем аргументам*
2) $\forall i \in \overline{1,n}\ :\ \lim\limits_{x_i \to -\infty} F_{\{\xi_i\}_{i=1}^n}(x_1, x_2, \dots, x_n) = 0$
3) $\lim\limits_{x_1 \to +\infty} F_{\{\xi_i\}_{i=1}^n}(x_1, x_2, \dots, x_n) = F_{\{\xi_i\}_{i=2}^n}(x_2, \dots, x_n)$ - *маргинальные распределения*

#### Доказательство.

1) Зафиксируем все аргументы, кроме $i$-го. Пусть $x_i \le y_i$, тогда: $\{\xi_i \le x_i\} \subseteq \{\xi_i \le y_i\}$, следовательно: $\bigcap\limits_{j=1}^n \{\xi_j \le x_j\} \subseteq \{\xi_i \le y_i\} \cap \bigcap\limits_{j \neq i} \{\xi_j \le x_j\}$. В силу монотонности вероятности:$$F(x_1, \ldots, x_i, \ldots, x_n) \le F(x_1, \ldots, y_i, \ldots, x_n)$$
2) Зафиксируем все аргументы, кроме $i$-го. Рассмотрим последовательность $y_{k} \to -\infty$, тогда события $A_k = \bigcap\limits_{j=1}^n \{\xi_j \le x_k\}$ образуют убывающую последовательность, причём $\bigcap\limits_{k=1}^\infty A_k = \varnothing$ так как при $x_i \to -\infty$ множество $\{\xi_i \le x_i\}$ стремится к пустому множеству. По непрерывности вероятностной меры: $$\lim_{x_i \to -\infty} F(x_1, \ldots, x_n) = \lim_{k \to \infty} P(A_k) = P(\varnothing) = 0$$
3) Рассмотрим предел: $\lim\limits_{x_1 \to +\infty} F_{\xi_1,\ldots,\xi_n}(x_1, x_2, \ldots, x_n) =$ $\lim\limits_{x_1 \to +\infty} P(\xi_1 \le x_1, \xi_2 \le x_2, \ldots, \xi_n \le x_n) =$ $P(\xi_2 \le x_2, \ldots, \xi_n \le x_n) =$ $F_{\xi_2,\ldots,\xi_n}(x_2, \ldots, x_n)$ так как событие $\{\xi_1 \le x_1\}$ при $x_1 \to +\infty$ стремится к достоверному событию $\Omega$. Аналогично для любого другого аргумента.

## Плотность совместного распределения

Если распределение можно представить в виде: $$F_{\{\xi_i\}_{i=1}^n}(x_1, x_2, \dots, x_n) = \int\limits_{\bigcap\limits_{i=1}^n \{\xi_i \leq x_i\}}p_{\{\xi_i\}_{i=1}^n} dP$$то ==Опр.== $p_{\{\xi_i\}_{i=1}^n}$ - плотность совместного распределения СВ $\{\xi_i\}_{i=1}^n$

### Критерий независимости СВ через плотность
$$\xi\ \text{и}\ \eta\ -\ \text{независимые СВ} \Longleftrightarrow F_{\xi, \eta}(x, y) = F_\xi(x) \cdot F_\eta(y) \Longleftrightarrow p_{\xi, \eta}(x, y) = p_\xi(x) \cdot p_\eta(y)\ \ (\text{если}\ \exists p_{\xi, \eta})$$
#### Доказательство

$(1) \Rightarrow (2)$: По определению независимости: $P(\xi \le x, \eta \le y) =$$P(\xi \le x) \cdot P(\eta \le y) =$ $F_\xi(x) \cdot F_\eta(y)$

$(2) \Rightarrow (1)$: $\forall x,y$: $P(\xi \le x, \eta \le y) =$ $F_\xi(x) F_\eta(y) = P(\xi \le x) P(\eta \le y)$
Класс множеств вида $(-\infty, x] \times (-\infty, y]$ порождает борелевскую $\sigma$-алгебру на $\mathbb{R}^2$. По теореме о единственности, $\forall A,B \in \mathcal{B}(\mathbb{R})$: $P(\xi \in A, \eta \in B) = P(\xi \in A) P(\eta \in B)$ что и означает независимость.

$(2) \Rightarrow (3)$ (при существовании плотности):$$F_{\xi,\eta}(x,y) = \int_{-\infty}^x \int_{-\infty}^y p_{\xi,\eta}(u,v) dv du = \left( \int_{-\infty}^x p_\xi(u) du \right) \left( \int_{-\infty}^y p_\eta(v) dv \right) = \int_{-\infty}^x \int_{-\infty}^y p_\xi(u) p_\eta(v) dv du$$
Дифференцируя по $x$ и $y$, получаем $p_{\xi,\eta}(x,y) = p_\xi(x) p_\eta(y)$.

$(3) \Rightarrow (2)$:$$F_{\xi,\eta}(x,y) = \int_{-\infty}^x \int_{-\infty}^y p_\xi(u) p_\eta(v) dv du = \left( \int_{-\infty}^x p_\xi(u) du \right) \left( \int_{-\infty}^y p_\eta(v) dv \right) = F_\xi(x) F_\eta(y)$$

### Свойства плотности совместного распределения
- Для простоты рассмотрим двумерный случай при $\xi = \xi_1$ и $\eta = \xi_2$, но факты ниже можно обобщить на n-мерный случай

1) $p_{\xi, \eta} \geq 0$
2) Если $F_{\xi, \eta} \in \mathbb{C}^3(\mathbb{R}^2)$ $\Rightarrow$ $\exists p_{\xi, \eta} = \frac{\partial^2F_{\xi, \eta}}{\partial x \partial y} = \frac{\partial^2F_{\xi, \eta}}{\partial y \partial x}$
3) $\exists p_{\xi, \eta}$ $\Rightarrow$ $\exists p_{\xi}$ и $\exists p_{\eta}$
4) $\exists p_{\xi}$ и $\exists p_{\eta}$ и при этом $\xi$ и $\eta$ - независимые $\Rightarrow$ $\exists p_{\xi, \eta} = p_{\xi} \cdot p_{\eta}$
5) $P((\xi, \eta) \in B) = \int\limits_{B} p_{\xi, \eta} dP$
6) $f \in \mathcal{M}_2$ $\Rightarrow$ $\mathbb{E}f = \int\limits_{\mathbb{R}^2}f(x, y)p_{\xi, \eta}dx dy$
7) $\int\limits_{\mathbb{R}^2}p_{\xi, \eta}dx dy = 1$
#### Доказательство

1) Для $\forall$ прямоугольника $[a,b] \times [c,d]$:$$P(a < \xi \le b, c < \eta \le d) = \int\limits_a^b \int\limits_c^d p_{\xi,\eta}(x,y) dy dx \ge 0$$Если бы в некоторой точке $(x_0,y_0)$ плотность была отрицательна, то в силу непрерывности (или измеримости) нашлась бы окрестность, где она отрицательна, и интеграл по этой окрестности был бы отрицательным, что противоречит неотрицательности вероятности

2) По определению функции совместного распределения:$$F_{\xi,\eta}(x,y) = \int\limits_{-\infty}^x \int\limits_{-\infty}^y p_{\xi,\eta}(u,v) dv du$$Продифференцируем по $y$:$$\frac{\partial F_{\xi,\eta}}{\partial y}(x,y) = \int\limits_{-\infty}^x p_{\xi,\eta}(u,y) du$$Продифференцируем по $x$:$$\frac{\partial^2 F_{\xi,\eta}}{\partial x \partial y}(x,y) = p_{\xi,\eta}(x,y)$$В силу Т. Шварца о равенстве смешанных производных:$$\frac{\partial^2 F_{\xi,\eta}}{\partial x \partial y} = \frac{\partial^2 F_{\xi,\eta}}{\partial y \partial x}$$
3) Рассмотрим маргинальную функцию распределения $\xi$:$$F_\xi(x) = \lim_{y \to +\infty} F_{\xi,\eta}(x,y) = \lim_{y \to +\infty} \int\limits_{-\infty}^x \int\limits_{-\infty}^y p_{\xi,\eta}(u,v) dv du$$по теореме Лебега о мажорируемой сходимости:$$F_\xi(x) = \int\limits_{-\infty}^x \left( \int\limits_{-\infty}^{+\infty} p_{\xi,\eta}(u,v) dv \right) du$$Следовательно, $\xi$ имеет плотность $p_\xi(u) = \int\limits_{-\infty}^{+\infty} p_{\xi,\eta}(u,v) dv$. Аналогично для $\eta$.

4) Для независимых $\xi$ и $\eta$: $F_{\xi,\eta}(x,y) = F_\xi(x) \cdot F_\eta(y)$. Подставим интегральное представление:$$F_{\xi,\eta}(x,y) = \left( \int\limits_{-\infty}^x p_\xi(u) du \right) \left( \int\limits_{-\infty}^y p_\eta(v) dv \right) = \int\limits_{-\infty}^x \int\limits_{-\infty}^y p_\xi(u) p_\eta(v) dv du$$По определению, это означает, что $p_{\xi,\eta}(u,v) = p_\xi(u) p_\eta(v)$ является плотностью совместного распределения.

5) Для прямоугольников $B = (a,b] \times (c,d]$ утверждение следует из определения:$$P(a < \xi \le b, c < \eta \le d) = \int\limits_a^b \int\limits_c^d p_{\xi,\eta}(x,y) dy dx$$Класс прямоугольников порождает борелевскую $\sigma$-алгебру $\mathcal{B}(\mathbb{R}^2)$ и является $\pi$-системой. Меры $\mu_1(B) = P((\xi,\eta) \in B)$ и $\mu_2(B) = \int_B p_{\xi,\eta}(x,y) dx dy$ совпадают на прямоугольниках. По теореме о единственности меры, они совпадают на всей $\mathcal{B}(\mathbb{R}^2)$.

6) Для индикаторных функций $f(x,y) = \mathbb{1}_B(x,y)$ утверждение следует из свойства 5:$$\mathbb{E}[\mathbb{1}_B(\xi,\eta)] = P((\xi,\eta) \in B) = \int\limits_B p_{\xi,\eta}(x,y) dx dy = \int\limits_{\mathbb{R}^2} \mathbb{1}_B(x,y) p_{\xi,\eta}(x,y) dx dy$$По линейности, утверждение верно для дискретных функций. Для неотрицательных измеримых функций применяем теорему Леви. Для произвольных интегрируемых функций представляем $f = f^+ - f^-$ и используем линейность.

7) $$\int\limits_{\mathbb{R}^2} p_{\xi,\eta}(x,y) dx dy = P((\xi,\eta) \in \mathbb{R}^2) = P(\Omega) = 1$$

### Неслучайная функция от СВ

Пусть $\xi$ - СВ, а $f \in \mathcal{M}_1$ - инъективная и всюдуопределённая.
$$\text{Пусть}\ \begin{cases} F'_\xi = p_\xi\\ \eta = f \circ \xi \end{cases}\ \ \ \ \text{тогда}\ p_\eta = \frac{F'_\xi \circ f^{-1}}{f'}$$
#### Доказательство.

$f$ - инъективна $\Rightarrow$ $\exists$ всюдуопределённая $f^{-1}$, тогда $F_\eta(x) =$ $P(\eta \leq x)$ $= P(\xi \leq f^{-1}(x)) =$ $F_\xi(f^{-1}(x))$, продифференцировав обе части равенства (мы можем в силу $F'_\xi = p_\xi$ и измеримости $f$) получим плотность распределения для $\eta$

---
<div style="page-break-after: always;"></div>


## <h2 id="p3p4"><center>Характеристическая функция СВ (б/д)</center></h2>

> [!NOTE] Заметим
> Заметим, что $\mathbb{C} \cong \mathbb{R}^2$, поэтому можно определить комплекснозначную СВ:

==Опр.== **Комплексная СВ** - случайный вектор размера 2, который можно записать в комплексной форме: $Z = (\xi,\ \eta)$ $\Rightarrow$ $Z = \xi + i\eta$

- Над значениями комплексной СВ можно совершать все те же операции, что над комплексными числами.

==Опр.== $\mathbb{E}Z = \mathbb{E}\xi + i\mathbb{E}\eta$

### Свойства комплексного матожидания

1) Свойства обычного матожидания
2) Комплексная линейность
3) $|\mathbb{E}Z| \leq \mathbb{E}|Z|$

## Характеристическая функция

==Опр.== **Характеристическая функция (ХФ) СВ** $\chi_\xi(t) = \mathbb{E}e^{it\xi}$

### Эквивалентные формулы ХФ

1) $\chi_\xi(t) = \mathbb{E}e^{it\xi}$
2) $\chi_\xi(t) = \mathbb{E}\cos(t\xi) + i\mathbb{E}\sin(t\xi)$
3) $\chi_\xi(t) = \int\limits_{\Omega}e^{it\xi} P(d\omega)$
4) $\chi_\xi(t) = \int\limits_{\mathbb{R}}e^{itx} dF_\xi(x)$
5) $\chi_\xi(t) = \int\limits_{\mathbb{R}}e^{itx} p_\xi(x)dx$

### Свойства ХФ

1) $\chi_\xi(0) = 1$
2) $|\chi_\xi(t)| \leq 1$
3) $\chi_\xi(t)$ равномерно непрерывна на $\mathbb{R}$
4) $\chi_{a\xi + b}(t) = e^{itb} \chi_{\xi}(at)$
5) $\chi_{\sum\limits_{k=1}^n\xi_k}(t) = \prod\limits_{k=1}^n \chi_{\xi_k}(t)$
6) Если $\exists$ m-й момент $\xi$, то $\chi_\xi(t) = \sum\limits_{k=0}^m \frac{i^k\mathbb{E}\xi^k}{k!}t^k + o(t^m),\ t \to 0$ (Если существуют все моменты $x$, то сумма обратится в ряд)
7) $\overline{\chi_\xi(t)} = \chi_{\xi}(-t) = \chi_{-\xi}(t)$
8) $\chi_\xi(t)$ неотрицательная в комплексном смысле

## Взаимное обращение ХФ и распределения

Восстановить плотность распределение (и само распределение) по ХФ можно, если:

1) $\int\limits_{\mathbb{R}}\chi_\xi(t)dt$ сходится абсолютно ($\chi_\xi \in \mathcal{L}_1(\mathbb{R})$)
- тогда $p_\xi(x) = \frac{1}{2\pi}\int\limits_{\mathbb{R}}e^{-itx}\chi_{\xi}(t)dt$ *(обратное преобразование Фурье)*

2) Применить *регуляризацию*

==Опр.== **Регуляризация** - превращение не абсолютно интегрируемую функцию в абсолютно интегрируемую с сохранением основных свойств

Для ХФ регуляризация выглядит так:
$\chi_\xi(t, \sigma) = \chi_\xi(t) \cdot e^{\frac{-(t\sigma)^2}{2}}$
$p_\xi(x, \sigma) = \frac{1}{2\pi}\int\limits_{\mathbb{R}}e^{-itx}\chi_{\xi}(t, \sigma)dt$ 
$p_\xi(x) = \lim\limits_{\sigma \to 0}p_\xi(x, \sigma)$

3) $\chi_\xi$ дискретна
- Восстанавливать по её *разбиению*

### Свёртка плотностей

Если $\xi$ и $\eta$ - независимые СВ и $\exists p_\xi$ и $\exists p_\eta$, то:$$\exists p_{\xi + \eta}(x) = (p_\xi\ *\ p_\eta)(t) := \int\limits_{\mathbb{R}} p_\xi(x - y)p_{\eta}(y)dy$$

---
<div style="page-break-after: always;"></div>


## <h2 id="p3p5"><center>Табличные виды распределений</center></h2>
## <h3 id="p3p5p1"><center>Распределение Бернулли</center></h3>

==Опр.==  СВ имеет распределение Бернулли с параметром $p$ ($\xi \sim Ber(p)$) $\Leftrightarrow$ $\begin{cases} P(\xi = 1) = p\\ P(\xi = 0) = 1 - p = q \end{cases}$

![[Pasted image 20251218184906.png]]
### Известные значения распределения
#### Матожидание

$\mathbb{E}\xi = q \cdot 0 + p \cdot 1 = p$

#### Дисперсия

$\mathbb{D}\xi = \mathbb{E}\xi^2 - p^2 = p \cdot (1 - p) = pq$
#### Характеристическая функция

$\chi_\xi(t) = e^{0}q + e^{it}p = q + e^{it}p$

---

## <h3 id="p3p5p2"><center>Биномиальное распределение</center></h3>

==Опр.== СВ имеет биномиальное распределение с параметрами $n$ и $p$ ($\xi \sim Bin(n, p)$) $\Leftrightarrow$ $\forall k \in \overline{0, n}\ :\ P(\xi = k) = C_n^kp^k(1-p)^{n-k} = C_n^kp^kq^{n-k}$

> [!NOTE] Замечание
> 1) $Ber(p) \sim Bin(1, p)$
> 2) $Bin(n, p)$ можно представить в виде суммы НОРСВ бернуллевских СВ

![[Pasted image 20251218185226.png]]
### Известные значения распределения
#### Матожидание

$\mathbb{E}\xi =$ $\sum\limits_{k=0}^nkC_n^kp^kq^{n-k} =$ $\sum\limits_{k=0}^n\frac{n!}{(k-1)!(n-k)!}p^kq^{n-k} =$ $np \downarrow \sum\limits_{k=1}^n\frac{(n-1)!}{(k-1)!(n-k)!}p^{k-1}q^{n-k}\uparrow$ $= np\sum\limits_{k=0}^{n-1}C_{n-1}^kp^{k}q^{(n-1)-k}$ $= np(p + q)^{n-1}$ $= np$

#### Дисперсия

Заметим, что $\xi = \sum\limits_{i=1}^n \xi_i,\ \forall i:\ \xi_i \sim Ber(p)$, и $\{\xi_i\}_{i=1}^n$ независимы
То есть $\mathbb{D}\xi = \mathbb{D}\left(\sum\limits_{i=1}^n \xi_i\right) = \sum\limits_{i=1}^n \mathbb{D}\xi_i = n\,\mathbb{D}\xi_1 = npq$ 
#### Характеристическая функция

Заметим, что $\xi = \sum\limits_{i=1}^n \xi_i,\ \forall i:\ \xi_i \sim Ber(p)$, и $\{\xi_i\}_{i=1}^n$ независимы, тогда $\chi_\xi(t) = \mathbb{E}e^{it\xi} = \mathbb{E}e^{it \sum\limits_{i=1}^n \xi_i} = \mathbb{E}\prod\limits_{i=1}^n e^{it\xi_i}$ ${=} \prod\limits_{i=1}^n \mathbb{E}e^{it\xi_i} = \left(\mathbb{E}e^{it\xi_1}\right)^n = (q + p e^{it})^n$

---

## <h3 id="p3p5p3"><center>Распределение Пуассона</center></h3>

==Опр.== СВ имеет распределение Пуассона с параметром $\lambda$ ($\xi \sim Pois(\lambda)$) $\Leftrightarrow$ $\forall k \in \mathbb{N}_0\ :\ P(\xi = k) = e^{-\lambda} \cdot \frac{\lambda^k}{k!}$

![[Pasted image 20251218191259.png]]
### Известные значения распределения
#### Матожидание

$\mathbb{E}\xi =$ $\sum\limits_{k=0}^{\infty}k \cdot e^{-\lambda}\frac{\lambda^k}{k!} =$ $e^{-\lambda}\sum\limits_{k=1}^{\infty}k \frac{\lambda^k}{k!} =$ $e^{-\lambda}\sum\limits_{k=1}^{\infty}\frac{\lambda^k}{(k-1)!} =$ $e^{-\lambda}\lambda\sum\limits_{k=1}^{\infty}\frac{\lambda^{k-1}}{(k-1)!} =$ $e^{-\lambda}\lambda e^{\lambda} =$ $\lambda$

#### Дисперсия

$\mathbb{D}\xi = \mathbb{E}\xi^2 - (\mathbb{E}\xi)^2$ $= \mathbb{E}(\xi(\xi - 1)) + \mathbb{E}\xi - \lambda^2 =$ $\sum\limits_{k=0}^{\infty}k(k-1)e^{-\lambda}\frac{\lambda^k}{k!} + \lambda - \lambda^2 =$ $e^{-\lambda}\sum\limits_{k=2}^{\infty}\frac{\lambda^k}{(k-2)!} + \lambda - \lambda^2$ $= e^{-\lambda}\lambda^2\sum\limits_{k=2}^{\infty}\frac{\lambda^{k-2}}{(k-2)!} + \lambda - \lambda^2$ $= e^{-\lambda}\lambda^2 e^{\lambda} + \lambda - \lambda^2$ $= \lambda$

#### Характеристическая функция

$\chi_\xi(t) =$ $\mathbb{E}e^{it\xi} =$ $\sum\limits_{k=0}^{\infty}e^{itk}e^{-\lambda}\frac{\lambda^k}{k!} =$ $e^{-\lambda}\sum\limits_{k=0}^{\infty}\frac{(\lambda e^{it})^k}{k!} =$ $e^{-\lambda}e^{\lambda e^{it}} =$ $e^{\lambda(e^{it} - 1)}$`

---

## <h3 id="p3p5p4"><center>Равномерное распределение</center></h3>

==Опр.== СВ имеет равномерное распределение на *(измеримом)* множестве $A$ ($\xi \sim U_A$) $\Leftrightarrow$ $\exists p_\xi(x) = \frac{1}{\mu(A)}\mathbb{1}_A$

> [!example] Частный случай
> В случае равномерного распределения на отрезке $[a; b]$ выполняется $\exists p_\xi(x) = \frac{1}{b - a}\mathbb{1}_{[a; b]}$
> 
> ![[Pasted image 20251218192550.png]]

### Известные значения распределения
#### Матожидание

$\mathbb{E}\xi = \int\limits_{-\infty}^{+\infty}x p_\xi(x)\,dx = \frac{1}{\mu(A)} \int\limits_{A} x d\mu$

В случае отрезка:
$\mathbb{E}\xi = \int\limits_{-\infty}^{+\infty}x p_\xi(x)\,dx = \int\limits_a^b x \cdot \frac{1}{b-a}\,dx = \frac{1}{b-a}\int\limits_a^b x\,dx = \frac{1}{b-a}\cdot\frac{b^2 - a^2}{2} = \frac{a + b}{2}$

#### Дисперсия *(для равномерного на отрезке)*

$\mathbb{D}\xi = \mathbb{E}\xi^2 - (\mathbb{E}\xi)^2 =$ $- \left(\frac{a + b}{2}\right)^2 + \int\limits_{-\infty}^{+\infty}x^2 p_\xi(x)\,dx =$ $- \left(\frac{a + b}{2}\right)^2 + \int\limits_a^b x^2 \cdot \frac{1}{b-a}\,dx =$ $- \left(\frac{a + b}{2}\right)^2 + \frac{1}{b-a}\int\limits_a^b x^2\,dx =$ $- \left(\frac{a + b}{2}\right)^2 + \frac{1}{b-a}\cdot\frac{b^3 - a^3}{3}$ $= \frac{b^3 - a^3}{3(b-a)} - \left(\frac{a + b}{2}\right)^2 =$ $\frac{(b-a)(b^2 + ab + a^2)}{3(b-a)} - \left(\frac{a + b}{2}\right)^2 =$ $\frac{a^2 + ab + b^2}{3} - \left(\frac{a + b}{2}\right)^2$ $= \frac{a^2 + ab + b^2}{3} - \frac{a^2 + 2ab + b^2}{4}$ $= \frac{4(a^2 + ab + b^2) - 3(a^2 + 2ab + b^2)}{12} =$ $\frac{a^2 - 2ab + b^2}{12} =$ $\frac{(b - a)^2}{12}$

#### Характеристическая функция *(для равномерного на отрезке)*

$\chi_\xi(t) =$ $\mathbb{E}e^{it\xi} =$ $\int\limits_{-\infty}^{+\infty}e^{itx} p_\xi(x)\,dx =$ $\int\limits_a^b e^{itx} \cdot \frac{1}{b-a}\,dx$ $= \frac{1}{b-a}\int\limits_a^b e^{itx}\,dx$ $= \frac{1}{b-a}\cdot\frac{e^{itx}}{it}\Big|_a^b$ $= \frac{1}{b-a}\cdot\frac{e^{itb} - e^{ita}}{it} =$ $\frac{e^{itb} - e^{ita}}{it(b-a)}$

---

## <h3 id="p3p5p5"><center>Экспоненциальное распределение</center></h3>

==Опр.==  СВ имеет экспоненциальное распределение с параметром $\lambda$ ($\xi \sim exp(\lambda)$) $\Leftrightarrow$ $\exists p_\xi(x) = \lambda e^{-\lambda x}$

![[Pasted image 20251219153744.png]]
### Известные значения распределения
#### Функция распределения
$F_\xi(x) =$ $\mathbb{P}(\xi \le x) =$ $\int\limits_{-\infty}^{x} \theta(x) p_\xi(t)\,dt =$ $\theta(x) \int\limits_{0}^{x}\lambda e^{-\lambda t}\,dt =$ $\theta(x) \left.-e^{-\lambda t}\right|_0^x$ = $\theta(x)(1 - e^{-\lambda x})$
#### Матожидание
$\mathbb{E}\xi =$ $\int\limits_{-\infty}^{+\infty}x p_\xi(x)\,dx$ $= \int\limits_0^{+\infty}x\lambda e^{-\lambda x}\,dx$ $= \lambda\int\limits_0^{+\infty}x e^{-\lambda x}\,dx =$ $\lambda\left(-\frac{x}{\lambda}e^{-\lambda x}\Big|_0^{+\infty} + \int\limits_0^{+\infty}\frac{1}{\lambda}e^{-\lambda x}\,dx\right)$ $= \lambda\left(0 + \frac{1}{\lambda}\left(-\frac{1}{\lambda}e^{-\lambda x}\Big|_0^{+\infty}\right)\right)$ $= \lambda\cdot\frac{1}{\lambda}\cdot\frac{1}{\lambda}$ $= \frac{1}{\lambda}$

#### Дисперсия
$\mathbb{D}\xi =$ $\mathbb{E}\xi^2 - (\mathbb{E}\xi)^2 =$ $\int\limits_{-\infty}^{+\infty}x^2 p_\xi(x)\,dx - \frac{1}{\lambda^2} =$ $\int\limits_0^{+\infty}x^2\lambda e^{-\lambda x}\,dx - \frac{1}{\lambda^2}$ $= \lambda\int\limits_0^{+\infty}x^2 e^{-\lambda x}\,dx - \frac{1}{\lambda^2}$ $= \lambda\left(-\frac{x^2}{\lambda}e^{-\lambda x}\Big|_0^{+\infty} + \int\limits_0^{+\infty}\frac{2x}{\lambda}e^{-\lambda x}\,dx\right) - \frac{1}{\lambda^2}$ $= \lambda\cdot\frac{2}{\lambda}\int\limits_0^{+\infty}x e^{-\lambda x}\,dx - \frac{1}{\lambda^2}$ $= 2\int\limits_0^{+\infty}x e^{-\lambda x}\,dx - \frac{1}{\lambda^2}$ $= \frac{2}{\lambda^2} - \frac{1}{\lambda^2}$ $= \frac{1}{\lambda^2}$

#### Характеристическая функция
$\chi_\xi(t) =$ $\mathbb{E}e^{it\xi}$ $= \int\limits_{-\infty}^{+\infty}e^{itx}p_\xi(x)\,dx$ $= \int\limits_0^{+\infty}e^{itx}\lambda e^{-\lambda x}\,dx$ $= \lambda\int\limits_0^{+\infty}e^{-(\lambda - it)x}\,dx$ $= \lambda\left(-\frac{1}{\lambda - it}e^{-(\lambda - it)x}\Big|_0^{+\infty}\right)$ $= \lambda\cdot\frac{1}{\lambda - it}\left(0 - (-1)\right)$ $= \frac{\lambda}{\lambda - it}$

---

## <h3 id="p3p5p6"><center>Треугольное распределение</center></h3>

==Опр.== СВ имеет треугольное распределение на отрезке $[a; b]$ с модой $c$ ($\xi \sim \text{T}(a, b, c)$) $\Leftrightarrow$ $\exists p_\xi(x) = \begin{cases} \frac{2(x-a)}{(b-a)(c-a)}, & a \le x \le c \\ \frac{2(b-x)}{(b-a)(b-c)}, & c \le x \le b \\ 0, & \text{else} \end{cases}$

> [!example] Частный случай
> Симметричное треугольное распределение при $c = \frac{a+b}{2}$:
> $$p_\xi(x) = \frac{2}{b-a}\left(1 - \frac{|x - \frac{a+b}{2}|}{\frac{b-a}{2}}\right)$$
> 
> ![[Pasted image 20260219194815.png]]

### Известные значения распределения
#### Функция распределения
$F_\xi(x) = \begin{cases} 0, & x < a \\ \frac{(x-a)^2}{(b-a)(c-a)}, & a \le x \le c \\ 1 - \frac{(b-x)^2}{(b-a)(b-c)}, & c \le x \le b \\ 1, & x > b \end{cases}$
#### Матожидание
$\mathbb{E}\xi = \int\limits_{-\infty}^{+\infty} x p_\xi(x)\,dx = \frac{a + b + c}{3}$
Для симметричного случая: $\mathbb{E}\xi = \frac{a+b}{2}$
#### Дисперсия
$\mathbb{D}\xi = \frac{a^2 + b^2 + c^2 - ab - ac - bc}{18}$
Для симметричного случая: $\mathbb{D}\xi = \frac{(b-a)^2}{24}$
#### Характеристическая функция
$\chi_\xi(t) = \frac{2(e^{ict}(c-b) + e^{ibt}(b-c) + e^{iat}(c-a) + e^{ict}(a-c))}{(b-a)(c-a)(b-c)t^2}$

---

## <h3 id="p3p5p7"><center>Распределение Коши</center></h3>

==Опр.== СВ имеет распределение Коши с параметрами сдвига $x_0$ и масштаба $\gamma > 0$ ($\xi \sim C(x_0, \gamma)$) $\Leftrightarrow$ $\exists p_\xi(x) = \frac{1}{\pi\gamma\left(1 + \left(\frac{x-x_0}{\gamma}\right)^2\right)} = \frac{1}{\pi}\left(\frac{\gamma}{(x-x_0)^2 + \gamma^2}\right)$

> [!NOTE] Замечания
> 1) Стандартное распределение Коши: $x_0 = 0$, $\gamma = 1$
> 2) В физике известно как распределение Лоренца
> 
![[Pasted image 20260220095812.png]]

### Известные значения распределения
#### Функция распределения
$F_\xi(x) = \frac{1}{\pi}arctg\left(\frac{x-x_0}{\gamma}\right) + \frac{1}{2}$
#### Матожидание
**Не существует** (интеграл $\int\limits_{-\infty}^{+\infty} |x| p_\xi(x)\,dx$ расходится)

#### Дисперсия
**Не существует** (т.к. не существует матожидание)

#### Медиана и мода
$\text{Med}(\xi) = x_0$, $\text{Mo}(\xi) = x_0$

#### Характеристическая функция
$\chi_\xi(t) = e^{\left(i x_0 t - \gamma |t|\right)}$

#### Свойства

1. **Устойчивость**: Сумма независимых величин с распределением Коши также имеет распределение Коши

---

## <h3 id="p3p5p8"><center>Нормальное распределение</center></h3>

==Опр.== СВ имеет нормальное распределение на с параметрами $a$ и $\sigma^2$ ($\xi \sim \mathcal{N}(a, \sigma^2)$) $\Leftrightarrow$ $\exists p_\xi(x) = \frac{1}{\sqrt{2\pi\sigma}}e^{-\frac{(x - a)^2}{2\sigma^2}}$

==Опр.== **Интеграл Лапласа** $\Phi_0(x) = \frac{1}{\sqrt{2\pi}}\int\limits_0^x e^{\frac{-u^2}{2}}du$

==Опр.== СВ имеет стандартное нормальное распределение $\Leftrightarrow$ $\xi \sim \mathcal{N}(0, 1)$

![[Pasted image 20251218194204.png]]
### Известные значения распределения
#### Матожидание
#### Матожидание *(стандартное нормальное)*
$\mathbb{E}\xi = \int\limits_{-\infty}^{+\infty}x p_\xi(x)\,dx = \frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^{+\infty}x e^{-\frac{x^2}{2}}dx$ 
Интеграл нечётной функции: $\frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^{+\infty}x e^{-\frac{x^2}{2}}dx = 0$ $\Rightarrow\ \mathbb{E}\xi = 0$

#### Матожидание *(общий случай)*
Пусть $\eta \sim \mathcal{N}(0, 1)$, тогда $\xi = a + \sigma\eta \Rightarrow \xi \sim \mathcal{N}(a, \sigma^2)$ $\mathbb{E}\xi = \mathbb{E}(a + \sigma\eta) = a + \sigma\mathbb{E}\eta = a + \sigma \cdot 0 = a$

#### Дисперсия
#### Дисперсия *(стандартное нормальное)* 
$\mathbb{D}\xi = \mathbb{E}\xi^2 - (\mathbb{E}\xi)^2 = \mathbb{E}\xi^2$
$\mathbb{E}\xi^2 = \int\limits_{-\infty}^{+\infty}x^2 p_\xi(x)\,dx = \frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^{+\infty}x^2 e^{-\frac{x^2}{2}}dx$ 
Рассмотрим $I = \int\limits_{-\infty}^{+\infty} e^{-\frac{x^2}{2}}dx$, тогда $$I \cdot I = (\int\limits_{\mathbb{R}} e^{-\frac{x^2}{2}}dx) \cdot (\int\limits_{\mathbb{R}} e^{-\frac{y^2}{2}}dy) = \int\limits_{\mathbb{R^2}} e^{-\frac{x^2 + y^2}{2}}dx$$
Пользуясь теоремой о замене переменной в кратном интеграле, перейдём в полярную СК:$$I^2 = \int\limits_{0}^{2\pi}\int\limits_{0}^{+\infty}e^{-\frac{\rho^2}{2}}\rho\ d\rho d\varphi = \int\limits_{0}^{2\pi}d\varphi\int\limits_{0}^{+\infty}e^{-\frac{\rho^2}{2}}\rho\ d\rho = 2\pi$$То есть $I = \sqrt{2\pi}$

Пусть $I'(\alpha) = \frac{d}{d\alpha}\int\limits_{-\infty}^{+\infty} e^{-\alpha x^2}dx = \int\limits_{-\infty}^{+\infty}(-x^2)e^{-\alpha x^2}dx$ 
При $\alpha = \frac{1}{2}$: $\int\limits_{-\infty}^{+\infty}x^2 e^{-\frac{x^2}{2}}dx = -I'\left(\frac{1}{2}\right)$, но $I(\alpha) = \int\limits_{-\infty}^{+\infty} e^{-\alpha x^2}dx = \sqrt{\frac{\pi}{\alpha}} \Rightarrow I'(\alpha) = -\frac{1}{2}\sqrt{\pi}\alpha^{-\frac{3}{2}}$ $\Rightarrow\ -I'\left(\frac{1}{2}\right) = \frac{1}{2}\sqrt{\pi}\left(\frac{1}{2}\right)^{-\frac{3}{2}} = \frac{1}{2}\sqrt{\pi}\cdot 2^{\frac{3}{2}} = \sqrt{2\pi}$ $\Rightarrow\ \mathbb{D}\xi = \frac{1}{\sqrt{2\pi}}\cdot \sqrt{2\pi} = 1$

#### Дисперсия *(общий случай)* 
$\mathbb{D}\xi = \mathbb{D}(a + \sigma\eta) = \mathbb{D}(\sigma\eta) = \sigma^2 \mathbb{D}\eta = \sigma^2 \cdot 1 = \sigma^2$

#### Характеристическая функция
#### Характеристическая функция *(стандартное нормальное)*

$\chi_\xi(t) =$ $\mathbb{E}e^{it\xi} =$ $\frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^{+\infty} e^{itx} e^{-\frac{x^2}{2}}dx =$ $\frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^{+\infty} e^{-\frac{x^2}{2} + itx}dx$ $-\frac{x^2}{2} + itx =$ $-\frac{1}{2}(x^2 - 2itx) =$ $-\frac{1}{2}(x^2 - 2itx + t^2) + \frac{t^2}{2} =$ $-\frac{(x - it)^2}{2} + \frac{t^2}{2}$ $\Rightarrow\ \chi_\xi(t) =$ $\frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^{+\infty} e^{-\frac{(x - it)^2}{2}} e^{\frac{t^2}{2}}dx =$ $e^{-\frac{t^2}{2}}\cdot \frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^{+\infty} e^{-\frac{(x - it)^2}{2}}dx$ $\int\limits_{-\infty}^{+\infty} e^{-\frac{(x - it)^2}{2}}dx =$ $\int\limits_{-\infty}^{+\infty} e^{-\frac{y^2}{2}}dy =$ $\sqrt{2\pi}$ $\Rightarrow$ $\chi_\xi(t) = e^{-\frac{t^2}{2}}$

#### Характеристическая функция *(общий случай)*
Пусть $\eta \sim \mathcal{N}(0, 1)$, тогда $\xi = a + \sigma\eta \Rightarrow \xi \sim \mathcal{N}(a, \sigma^2)$ $\Rightarrow$ $\chi_\xi(t) =$ $\mathbb{E}e^{it(a + \sigma\eta)} =$ $e^{ita - \frac{(\sigma t)^2}{2}}$

---
<div style="page-break-after: always;"></div>


# <h1 id="p4"><center>Последовательности случайных величин</center></h1>

## <h2 id="p4p1"><center>Лемма Бореля-Кантелли</center></h2>

Пусть $\{A_n\}_{n \in \mathbb{N}}$ - последовательность событий, тогда

1) Если $\sum\limits_{n=1}^{\infty}P(A_n) < \infty$, то $P(\overline{\lim}\limits_{n \to \infty} A_n) = 0$
2) Если $\{A_n\}_{n \in \mathbb{N}}$ независимые в совокупности и $\sum\limits_{n=1}^{\infty}P(A_n) = \infty$, то $P(\overline{\lim}\limits_{n \to \infty} A_n) = 1$

#### Доказательство

1) Пусть $\sum\limits_{n=1}^{\infty}P(A_n) < \infty$
Определим случайную величину $\xi = \sum\limits_{n=1}^\infty \mathbb{1}_{A_n}$ - количество событий $A_n$, в которые попал данный элементарный исход. По теореме о монотонной сходимости:
$$\mathbb{E}\xi = \sum\limits_{n=1}^\infty \mathbb{E}\mathbb{1}_{A_n} = \sum\limits_{n=1}^\infty P(A_n) < \infty$$

Так как математическое ожидание конечно, то $P(\xi < \infty) = 1$ (если бы с положительной вероятностью $\xi = \infty$, то и математическое ожидание было бы бесконечным). Заметим, что событие $\{\overline{\lim}\limits_{n \to \infty} A_n\}$ означает, что произошло бесконечно много событий $A_n$, то есть $\xi = \infty$, следовательно: $P(\overline{\lim}\limits_{n \to \infty} A_n) =$ $P(\xi = \infty) = 0$

2) Пусть $\{A_n\}_{n \in \mathbb{N}}$ независимы в совокупности и $\sum\limits_{n=1}^{\infty}P(A_n) = \infty$

Рассмотрим вероятность того, что ни одно из событий $\{A_k\}_{k=n}^N$ не произошло. В силу независимости:
$$P\left(\bigcap_{m=n}^{N} \overline{A}_m\right) = \prod_{m=n}^{N} P(\overline{A}_m) = \prod_{m=n}^{N} (1 - P(A_m))$$

Используем неравенство $1 - x \le e^{-x}$ для $x \ge 0$:
$$P\left(\bigcap_{m=n}^{N} \overline{A}_m\right) \le \prod_{m=n}^{N} e^{-P(A_m)} = \exp\left(-\sum_{m=n}^{N} P(A_m)\right)$$

Так как $\sum\limits_{n=1}^{\infty} P(A_n) = \infty$, то $\sum\limits_{m=n}^{N} P(A_m) \to \infty$ при $N \to \infty$, следовательно:
$$\lim_{N\to\infty} P\left(\bigcap_{m=n}^{N} \overline{A}_m\right) \le \lim_{N\to\infty} \exp\left(-\sum_{m=n}^{N} P(A_m)\right) = 0$$

Последовательность событий $\bigcap_{m=n}^{N} \overline{A}_m$ убывает при $N \to \infty$ к $\bigcap_{m=n}^{\infty} \overline{A}_m$. По непрерывности вероятностной меры:
$$P\left(\bigcap_{m=n}^{\infty} \overline{A}_m\right) = \lim_{N\to\infty} P\left(\bigcap_{m=n}^{N} \overline{A}_m\right) = 0$$

Теперь заметим, что:
$$\bigcup_{m=n}^{\infty} A_m = \overline{\bigcap_{m=n}^{\infty} \overline{A}_m} = 1 - P\left(\bigcap_{m=n}^{\infty} \overline{A}_m\right) = 1 - 0 = 1$$
Таким образом, $\forall n$ вероятность объединения событий, начиная с номера $n$, равна 1. Наконец, по определению верхнего предела:
$$\overline{\lim_{n\to\infty}} A_n = \bigcap_{n=1}^{\infty} \bigcup_{m=n}^{\infty} A_m$$

Последовательность $\bigcup\limits_{m=n}^{\infty} A_m$ убывает при $n \to \infty$, поэтому:
$$P\left(\overline{\lim_{n\to\infty}} A_n\right) = \lim_{n\to\infty} P\left(\bigcup_{m=n}^{\infty} A_m\right) = 1$$

---
<div style="page-break-after: always;"></div>


## <h2 id="p4p2"><center>Сходимости случайных величин</center></h2>

> [!question] Тема раздела
> Будем рассматривать последовательность СВ $\{\xi_n\}_{n=1}^{\infty}$ и исследовать к чему она стремится. В теории вероятностей есть разные виды сходимости, на диаграмме ниже показано какая следует из какой.

![[Pasted image 20251218112330.png]]
### <h3 id="p4p2p1"><center>Сходимость почти наверное</center></h3>

==Опр.== $\xi_n$ почти наверное *(почти всегда, почти всюду, almost sure, $\xi_n \xrightarrow[]{a. \forall} \xi$)* сходится к $\xi$ $\Leftrightarrow$ $P(\{\omega\ |\ \lim\limits_{n \to \infty}\xi_n(\omega) \neq \xi(\omega)\}) = 0$

> [!NOTE] Виды записи
> Данное событие эквивалентно следующей записи: $P(\lim\limits_{n \to \infty}\xi_n = \xi) = 1$, или такой: $P(\xi_n \to \xi) = 1$

### Эквивалентная формулировка сходимости почти наверное
$$P(\lim\limits_{n \to \infty}\xi_n = \xi) = 1\ \Longleftrightarrow\ \forall \varepsilon > 0\ :\ \lim\limits_{n \to \infty}P(\{\omega\ |\ \sup\limits_{m \geq n}|\xi_m-\xi| > \varepsilon\}) = 0$$
#### Доказательство

1) Так как $\xi_n \to \xi$ $\Leftrightarrow$ $\forall \epsilon > 0\ \exists N \in \mathbb{N}\ \forall m \geq N\ :\ |\xi_m - \xi| \leq \epsilon < 2\epsilon$, то$$\{\xi_n \to \xi\} = \bigcap\limits_{r=1}^{\infty}\bigcup\limits_{N=1}^{\infty}\bigcap\limits_{m \geq N}\{|\xi_m - \xi| \leq \frac{1}{r}\}$$
2) Противоположное событие получается отрицанием:$$\overline{\{\xi_n \to \xi\}} = \bigcup\limits_{r=1}^{\infty}\bigcap\limits_{N=1}^{\infty}\bigcup\limits_{m \geq N}\{|\xi_m - \xi| > \frac{1}{r}\}$$
3) Тогда $$P(\{\xi_n \to \xi\}) = 1 \Leftrightarrow P(\overline{\{\xi_n \to \xi\}}) = 0\Leftrightarrow \forall r \in \mathbb{N}\ :\ P(\{\bigcap\limits_{N=1}^{\infty}\bigcup\limits_{m \geq N}\{|\xi_m - \xi| > \frac{1}{r}\}) = 0$$
4) В силу монотонности последовательности событий $A_n = \bigcup\limits_{m \geq n}\{|\xi_m - \xi| > \frac{1}{r}\}$, получаем:$$A_n = \bigcup\limits_{m \geq n}\{|\xi_m - \xi| > \frac{1}{r}\} = \{\sup\limits_{m \geq n}|\xi_m - \xi| > \frac{1}{r}\}$$и$${P(\bigcap\limits_{n=1}^{\infty}A_n)} = \lim\limits_{n \to \infty}P(A_n)$$
5) Группируя 3 и 4 пункт получаем:$$P(\{\xi_n \to \xi\}) = 1 \Longleftrightarrow \forall r \geq 1\ :\ \lim\limits_{n \to \infty} P(\{\sup\limits_{m \geq n}|\xi_m - \xi| > \frac{1}{r}\}) = 0$$
6) 5 пункт равносилен необходимой формулировке поскольку $\forall r_1 > r_2$ верно $(|\xi_m - \xi| > \frac{1}{r_1}) \Rightarrow (|\xi_m - \xi| > \frac{1}{r_2})$

---

### <h3 id="p4p2p2"><center>Сходимость по вероятности</center></h3>

==Опр.== $\xi_n$ сходится по вероятности к $\xi$ $\Leftrightarrow$ $\xi_n \xrightarrow[]{\mathbb{P}} \xi$ $\Leftrightarrow$ $\forall \varepsilon > 0\ \lim\limits_{n \to \infty}P(|\xi_n - \xi| > \varepsilon) = 0$

==Опр.== $\xi_n$ **фундаментальна по вероятности** $\Leftrightarrow$ $\forall \varepsilon, \epsilon > 0\ \exists N \in \mathbb{N}\ \forall n, m \geq N\ :\ P(|\xi_n - \xi_m| > \varepsilon) < \epsilon$

### Сходимость по вероятности из сходимости почти наверное
$$P(\xi_n \to \xi) = 1\ \Longrightarrow\ \xi_n \xrightarrow[]{\mathbb{P}} \xi$$
#### Доказательство.

Заметим, что $\forall \varepsilon > 0\ \forall n \in \mathbb{N}\ :\ \{|\xi_n - \xi| > \varepsilon\} \subseteq \{\sup\limits_{m \geq n}|\xi_m - \xi| > \varepsilon\}$ $=\{|\xi_n - \xi| > \varepsilon\} \cup \{\sup\limits_{m > n}|\xi_m - \xi| > \varepsilon\}$, а далее, используя формулировку сходимости почти наверное через супремум и свойство счётной аддитивности вероятностной меры, получаем $P(\xi_n \to \xi) = 1\ \Longrightarrow\ \xi_n \xrightarrow[]{\mathbb{P}} \xi$

### Сходимость по вероятности фундаментальной последовательности

- $\xi_n \xrightarrow[]{\mathbb{P}} \xi$ $\Longleftrightarrow$ $\xi_n$ - фундаментальна по вероятности

#### Доказательство
###### Необходимость:
$P(|\xi_n - \xi_m| > 2\varepsilon) =$ $P(|\xi_n - \xi + \xi - \xi_m| > 2\varepsilon)$ $\leq P(|\xi_n - \xi| > \varepsilon) + P(|\xi_m - \xi| > \varepsilon) \to 0$ при $n, m \to \infty$

###### Достаточность:
Найдём по индукции такую подпоследовательность $\{\xi_{n_k}\}_{k=1}^{\infty}$, что она $\xi_{n_k}\xrightarrow[]{\mathbb{P}} \xi$:
1) Пусть $n_1 = 1$
2) Рассмотрим как найти $n_k$. Пусть $\epsilon = \varepsilon = \frac{1}{2^k}$. В силу фундаментальности последовательности $\exists N > n_{k-1}$ т.ч. $\forall s, t \geq N\ :\  P(|\xi_s - \xi_t| > \frac{1}{2^k}) < \frac{1}{2^k}$, тогда пусть $n_k = N$
3) По построению получилось: $\sum\limits_{k=1}^\infty P(|\xi_{n_{k+1}} - \xi_{n_{k}}| > \frac{1}{2^k}) < \sum\limits_{k=1}^\infty \frac{1}{2^k} = 1 < +\infty$, тогда по лемме Бореля-Кантелли $P(\lim\limits_{k \to \infty}\sup\{|\xi_{n_{k+1}} - \xi_{n_{k}}| > \frac{1}{2^k}\}) = 0$
4) Пусть $\xi = \xi_{n_1} + \sum\limits_{k=1}^{\infty} (\xi_{n_{k+1}} - \xi_{n_k})$ *(где ряд сходится и 0 в остальных точках)* $\Rightarrow$ так как ряд сходится почти всюду (множество точек расхождения имеет меру нуль), то $P(\xi_{n_k} \to \xi) = 1$
5) В силу фундаментальности последовательности $\forall k \geq n$: $P(|\xi_n - \xi| > 2\varepsilon) =$ $P(|\xi_n - \xi_{n_k} + \xi_{n_k} - \xi| > 2\varepsilon)$ $\leq P(|\xi_n - \xi_{n_k}| > \varepsilon) + P(|\xi - \xi_{n_k}| > \varepsilon) \to 0$ при $n, m \to \infty$

---

### <h3 id="p4p2p3"><center>Сходимость по распределению</center></h3>

==Опр.== $\xi_n$ **сходится по распределению** к $\xi$ $\Leftrightarrow$ $\xi_n \xrightarrow[]{d} \xi$ $\Leftrightarrow$ $\forall x$ - точка непрерывности $F_\xi$  $:\ \lim\limits_{n \to \infty}F_{\xi_n}(x) = F_{\xi}(x)$

### Сходимость по распределению из сходимости по вероятности
$$\xi_n \xrightarrow[]{\mathbb{P}} \xi\ \Longrightarrow\ \xi_n \xrightarrow[]{d} \xi$$
#### Доказательство.

Пусть $A_n = \{|\xi_n - \xi| \leq \varepsilon\}$, тогда $\omega \in A_n$ $\Leftrightarrow$ $\xi - \varepsilon \leq \xi_n \leq \xi + \varepsilon$. Заметим, что $\forall x \in \mathbb{R}$:
1) $\{\xi_n \leq x\} = \{\xi_n \leq x|A_n\} \sqcup \{\xi_n \leq x|\overline{A_n}\}  \subseteq \{\xi \leq x + \varepsilon\} \cup \overline{A_n}$
2) $\{\xi \leq x - \varepsilon\} = \{\xi \leq x - \varepsilon|A_n\} \sqcup \{\xi \leq x - \varepsilon|\overline{A_n}\} \subseteq \{\xi_n \leq x\} \cup \overline{A_n}$
Далее, выразим событие $\{\xi_n \leq x\}$ из обоих неравенств и применим свойство монотонности вероятностной меры:$$P(\xi \leq x - \varepsilon) - P(\overline{A_n}) \leq P(\xi_n \leq x) \leq P(\xi \leq x + \varepsilon) + P(\overline{A_n})$$И так как при $\xi_n \xrightarrow[]{\mathbb{P}} \xi$ верно $\lim\limits_{n \to \infty}A_n = \Omega$, то$$P(\xi \leq x - \varepsilon) \leq \overline{\lim}\limits_{n \to \infty}P(\xi_n \leq x) \leq \underline{\lim}\limits_{n \to \infty}P(\xi_n \leq x) \leq P(\xi \leq x + \varepsilon)$$то есть$$\underline{\lim}\limits_{n \to \infty}F_\xi(x) \leq \lim\limits_{n \to \infty}F_{\xi_n}(x) \leq \overline{\lim}\limits_{n \to \infty}F_\xi(x)$$и так как это верно для $\forall \varepsilon > 0$, то в точках непрерывности $F_\xi$ действительно $\lim\limits_{n \to \infty}F_{\xi_n}(x) = F_{\xi}(x)$

### Сходимость по вероятности из вырожденной сходимости по распределению

Пусть $\xi_n \xrightarrow[]{d} \xi$, причём $F_\xi$ *вырождена в точке $c$,* то есть:
1) $F_\xi(c-0)=0$
2) $F_\xi(c+0)=1$
Тогда $\xi_n \xrightarrow[]{\mathbb{P}} \xi$

#### Доказательство.

$F_\xi$ вырождена в точке $c$ $\Leftrightarrow$ $P(\xi = c) = 1$ $\Rightarrow$ $\lim\limits_{n \to \infty}P(c - \varepsilon < \xi_n \leq c + \varepsilon) =$ $\lim\limits_{n \to \infty}P(|\xi_n - c| > \varepsilon)$ $= 1$

---

### <h3 id="p4p2p4"><center>Сходимость по характеристике (слабая сходимость) (б/д)</center></h3>

==Опр.== $\xi_n$ **слабо сходится** к $\xi$ $\Leftrightarrow$ $\xi_n \xrightarrow[]{d} \xi$ $\Leftrightarrow$ $\forall t \in \mathbb{R}$ $:\ \lim\limits_{n \to \infty}\chi_{\xi_n}(x) = \chi_{\xi}(x)$

> [!tip] Эквивалентность слабой и по распределению сходимостей
> Слабая сходимость эквивалентна сходимости по распределению, поэтому будем их отождествлять. 

---

### <h3 id="p4p2p5"><center>Сходимость в среднем</center></h3>

==Опр.== **$\xi_n$ сходится в среднем порядка $r$ к $\xi$** $\Leftrightarrow$ $\xi_n \xrightarrow[]{r} \xi$ $\Leftrightarrow$ $\lim\limits_{n \to \infty}\mathbb{E}|\xi_n - \xi|^r = 0$

==Опр.== **$\xi_n$ сходится в $\mathcal{L}_1$ к $\xi$** $\Leftrightarrow$ $\xi_n \xrightarrow[]{r} \xi$ при $r = 1$

==Опр.== **$\xi_n$ сходится в $\mathcal{L}_2$ (сходится среднеквадратично) к $\xi$** $\Leftrightarrow$ $\xi_n \xrightarrow[]{r} \xi$ при $r = 2$

### Сходимость по вероятности из сходимости в среднем
$$\text{Если}\ r \geq 1,\ \text{то}\ \ \xi_n \xrightarrow[]{r} \xi\ \Longrightarrow\ \xi_n \xrightarrow[]{\mathbb{P}} \xi$$
#### Доказательство

Пусть $\eta_n = |\xi_n - \xi| \geq 0$, тогда по неравенству Маркова и следствию 1 из него для $f(x) = x^r$ - монотонно возрастающей на $\mathbb{R}$ верно что $\forall \varepsilon > 0\ :\ P(\eta > \varepsilon) \leq \frac{\mathbb{E}\eta^r}{\varepsilon^r}$ и тогда по теореме о предельном переходе в неравенстве: $0 \leq \lim\limits_{n \to \infty}P(|\xi_n - \xi| > \varepsilon) \leq \frac{1}{\varepsilon^2}\lim\limits_{n \to \infty}\mathbb{E}|\xi_n - \xi|^r = 0$ $\Rightarrow$
$\xi_n \xrightarrow[]{\mathbb{P}} \xi$

---
<div style="page-break-after: always;"></div>


## <h2 id="p4p3"><center>Законы больших чисел</center></h2>




<div style="page-break-after: always;">разрыв страницы</div>


<h2 id="Примечания"><center>Примечания</center></h2>

1) Оригинальный конспект в последней редакции можно найти на моём GitHub: https://github.com/Leg15Coder/Digital-garden
2) По всем найденным ошибкам и опечаткам можно писать в GH issues: https://github.com/Leg15Coder/Digital-garden/issues или мне в ЛС https://t.me/dimka_ryaz
