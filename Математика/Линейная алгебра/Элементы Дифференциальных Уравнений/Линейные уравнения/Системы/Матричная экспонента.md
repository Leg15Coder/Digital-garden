==Опр.== **Матричная экспонента** матрицы $A \in M_{n \times n}(\mathbb{R})$ - сумма формального ряда:$$e^A = \sum_{k=0}^\infty \frac{A^k}{k!}$$
### Теорема о сходимости

Ряд $e^A$ сходится абсолютно и равномерно на любом множестве $K_a = \{A \in Mat_{n \times n}(\mathbb{R}) \mid \|A\| = \sqrt{\sum\limits_{i, j = 1, 1}^{n, n}a_{i,j}} \le a\}$.
#### Доказательство

Используя свойство нормы $\|A^k\| \le \|A\|^k \le a^k$ и [[Многомерный анализ.pdf|признак Вейерштрасса]]: числовой ряд $\sum \frac{a^k}{k!}$ сходится к $e^a$, следовательно, матричный ряд сходится равномерно.

### Свойства матричной экспоненты

1. Если $A = \text{diag}(\lambda_1, \dots, \lambda_n)$, то $e^A = \text{diag}(e^{\lambda_1}, \dots, e^{\lambda_n})$
2. Если $A = \begin{pmatrix} B_1 & 0 & \dots 0 \\ 0 & B_2 & \dots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & B_m \end{pmatrix}$, где $\forall k \in \overline{1, m}\ :\ B_k \in Mat(\mathbb{R})$, то $e^A = \begin{pmatrix} e^{B_1} & 0 & \dots 0 \\ 0 & e^{B_2} & \dots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & e^{B_m} \end{pmatrix}$
3. Если $N \in Mat_{n \times n}(\mathbb{R})$ т.ч. $\exists n \in \mathbb{N}_0\ :\ N^n = 0$, то $e^N = \sum\limits_{k=0}^{n-1} \frac{N^k}{k!}$
4. Если $AB = BA$, то $e^{A+B} = e^A \cdot e^B$.
5. Если $\forall t \in \mathbb{R}\ :\ e^{(A+B)t} = e^{At}e^{Bt}$, то $AB = BA$
6. $Ae^A = e^AA$
7. Для $\forall$ матрицы $A$ матрица $e^A$ невырождена, при этом $(e^A)^{-1} = e^{-A}$.
8. Если $B = S^{-1}AS$, то $e^B = S^{-1}e^A S$.
9. $e^{J_k(\lambda)t} = e^{\lambda t} \cdot \begin{pmatrix} 1 & t & \frac{t^2}{2} & \dots & \frac{t^{n-1}}{(n-1)!} \\ 0 & 1 & t & \dots & \frac{t^{n-2}}{(n-2)!} \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & \dots & 1 \end{pmatrix}$
10. Если $A^T = -A$, то $(e^A)(e^A)^T = E$
11. Если $v$ - СВ матрицы $A$ с соотв. СЗ $\lambda$, то $v$ - СВ матрицы $e^A$ с соотв. СЗ $e^{\lambda}$
12. $\det(e^A) = e^{\text{tr} A}$.
13. $\frac{d}{dt} e^{At} = A e^{At} = e^{At} A$.

#### Доказательство

1. $A^k = \text{diag}(\lambda_1^k, \dots, \lambda_n^k)$, подставляя в ряд: $e^A =$ $\sum \frac{\text{diag}(\lambda_1^k, \dots, \lambda_n^k)}{k!} =$ $\text{diag}(e^{\lambda_1}, \dots, e^{\lambda_n})$
2. Заметим, что $A^k = \text{diag}(B_1^k, \dots, B_n^k)$, подставляя в ряд: $e^A =$ $\sum \frac{\text{diag}(B_1^k, \dots, B_n^k)}{k!} =$ $\text{diag}(e^{B_1}, \dots, e^{B_n})$
3. По условию $N^n = 0$, поэтому при $k \geq n$ имеем $N^k = 0$ и ряд для экспоненты обрывается
4. $e^{A+B} =$ $\sum\limits_{n=0}^\infty \frac{(A+B)^n}{n!} =$ $\sum\limits_{n=0}^\infty \sum\limits_{k=0}^n \frac{C_n^k A^k B^{n-k}}{n!} =$ $\sum\limits_{n=0}^\infty \sum\limits_{k=0}^n \frac{A^k}{k!} \frac{B^{n-k}}{(n-k)!}$. Это [[Многомерный анализ.pdf|произведение по Коши]] двух рядов $e^A$ и $e^B$
5. Если функции равны, то и их производные любого порядка - тоже. продифференцируем тождество 2 раза: $\frac{d^2}{dt^2}e^{(A+B)t} =$ $(A+B)^2e^{(A+B)t} =$ $\frac{d^2}{dt^2}(e^{At}e^{Bt}) =$ $\frac{d}{dt}(Ae^{At}e^{Bt} + e^{At}Be^{Bt}) =$ $A^2e^{At}e^{Bt} + Ae^{At}Be^{Bt} = Ae^{At}Be^{Bt} + e^{At}B^2e^{Bt}$. Это верно при $\forall t$, в частности при $t=0$: $(A+B)^2=$ $A^2 + AB + BA + B^2 =$ $A^2 + 2AB + B^2$ $\implies$ $AB = BA$
6. $Ae^A =$ $A(\sum\limits_{k=0}^\infty \frac{A^k}{k!}) =$ $\sum\limits_{k=0}^\infty \frac{A^{k+1}}{k!} =$ $(\sum\limits_{k=0}^\infty \frac{A^k}{k!})A =$ $e^AA$
7. Из п.4 при $B = -A$ получаем $e^{A}e^{-A}=$ $e^{A - A} =$ $e^0$ $= E$, значит $e^A$ обратима, причём обратная матрица - $e^{-A}$
8. $B^k =$ $(S^{-1}AS)^k =$ $S^{-1}A^k S$, подставляя в ряд: $e^B =$ $\sum \frac{S^{-1}A^k S}{k!} =$ $S^{-1}(\sum \frac{A^k}{k!})S =$ $S^{-1}e^A S$
9. Заметим, что $J_k(\lambda) = \lambda E + N$, где $N$ - нильпотентная матрица, у которой над главной диагональю стоят 1, а всё остальное - 0. По п.4 $e^{J_k(\lambda)t}$ $= e^{\lambda t E} e^{Nt}$ $= e^{\lambda t} e^{Nt} =$ \[по п.3\] $= e^{\lambda t} \cdot \sum\limits_{i=0}^{k-1} \frac{(Nt)^i}{i!}$ - это и есть матрица из условия, поскольку $N^k$ - матрица, в которой над главной диагональю на $k$-й диагонали стоят 1, а остальное - 0.
10. Заметим, что $e^{A^T} =$ $\sum\limits_{k=0}^\infty \frac{(A^T)^k}{k!}$ $= (e^A)^T$ в силу линейности транспонирования. При этом же $e^Ae^{A^T} =$ $e^A(e^{A})^T =$ $e^Ae^{-A}$ $=E$
11. $v$ - СВ, значит $Av = \lambda v$ $\Rightarrow$ $\forall k \geq 0\ :\ A^kv = \lambda^kv$ $\Rightarrow$ $e^Av =$ $(\sum\limits_{k=0}^\infty \frac{A^k}{k!})v =$ $\sum\limits_{k=0}^\infty \frac{A^kv}{k!} =$ $\sum_{k=0}^\infty \frac{\lambda^kv}{k!} =$ $e^{\lambda}v$ - доказано.
12. Через переход к ЖНФ ($A \to J$): $\det(e^A) =$ $\det(e^J) =$ $\prod \det(e^{J_k(\lambda_k)})$. Поскольку $e^{J_k}$ - верхнетреугольная матрица с $e^{\lambda_k}$ на диагонали, $\det(e^{J_k}) =$ $(e^{\lambda_k})^{k_j} =$ $e^{k_j \lambda_k}$. Итого: $\prod \det(e^{J_k(\lambda_k)}) =$ $e^{\sum k_j \lambda_k} = e^{\text{tr} A}$
13. По [[Многомерный анализ.pdf|теореме о дифференцировании функционального ряда]]: $\frac{d}{dt} \sum \frac{A^n t^n}{n!} =$ $\sum \frac{n A^n t^{n-1}}{n!} =$ $A \sum \frac{A^{n-1} t^{n-1}}{(n-1)!} =$ $A e^{At}$

### Решение [[Система линейных уравнений с постоянными коэффициентами|СЛДУ]] через экспоненту
#### Однородный случай

Для системы $\dot{x} = Ax$ с начальным условием $x(0) = x_0$ решение имеет вид:$$x(t) = e^{At}x_0$$
##### Проверка:
1. $\dot{x}(t) =$ $\frac{d}{dt}(e^{At}x_0) =$ $(A e^{At})x_0 =$ $A(e^{At}x_0) =$ $Ax(t)$.
2. $x(0) =$ $e^{A \cdot 0}x_0 =$ $E x_0 =$ $x_0$.

#### Неоднородный случай

Для системы $\dot{x} = Ax + b(t)$, с начальным условием $x(t_0) = x_0$:
$$x(t) = e^{A(t-t_0)}x_0 + \int_{t_0}^t e^{A(t-s)}b(s) ds$$
##### Проверка:
1. $\dot{x} =$ $Ae^{A(t - t_0)}x_0 + b(t) + \int\limits_{t_0}^t Ae^{A(t-s)}b(s) ds =$ $b(t) + A(e^{A(t - t_0)}x_0 \int\limits_{t_0}^t e^{A(t-s)}b(s) ds) =$ $b(t) + Ax(t)$
2. $x(t_0) =$ $e^{A(t_0 - t_0)} x_0 + \int\limits_{t_0}^{t_0}e^{A(t-s)}b(s) ds =$ $E x_0 + 0 =$ $x_0$

---
